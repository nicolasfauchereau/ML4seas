{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load external modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "# target variable \n",
    "target_var = 'TMEAN'\n",
    "\n",
    "# target type (anomalies ('anomalies') or terciles categories ('cat_3'))\n",
    "target_type = 'cat_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import pathlib\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = pathlib.Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../ml4seas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_root_dir\n",
    "from GCM import get_GCM_outputs, shift_dset_time, concat_GCMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### domain definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_def = {}\n",
    "domain_def['local'] = [150, 200, -50, -10]\n",
    "domain_def['regional'] = [90, 300, -65, 50]\n",
    "domain_def['ext_regional'] = [70, 300, -70, 60]\n",
    "# domain_def['ext_regional'] = [50, 300, -75, 60]\n",
    "domain_def['global'] = [0, 360, -70, 70]\n",
    "domain_def['tropics'] = [0, 360, -40, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the root path for the `data` folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='gdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCMs = ['ECMWF', 'UKMO', 'METEO_FRANCE', 'DWD', 'CMCC', 'NCEP_CFSv2', 'CanCM4i', 'GEM_NEMO', 'NASA_GEOSS2S', 'CanSIPSv2', 'JMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='gdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_X = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M\n",
      "number of files in the archive: 287\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_1993_02.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/T2M\n",
      "number of files in the archive: 264\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting NCEP_CFSv2\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M\n",
      "number of files in the archive: 420\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_1982_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CanCM4i\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M\n",
      "number of files in the archive: 396\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting GEM_NEMO\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M\n",
      "number of files in the archive: 432\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting NASA_GEOSS2S\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M\n",
      "number of files in the archive: 431\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_1981_02.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CanSIPSv2\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M\n",
      "number of files in the archive: 432\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting JMA\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M\n",
      "number of files in the archive: 456\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_1979_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2016_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_train, X_data_train_std, X_index_train, GCM_records_train, GCM_coords_train, scalers_dict = concat_GCMs(GCMs, var_name=var_X.upper(), period='hindcasts', rpath=rpath, domain='ext_regional', standardize=True, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now get the forecasts from the local drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M\n",
      "number of files in the archive: 28\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2017_09.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M\n",
      "number of files in the archive: 14\n",
      "Something wrong with the number of files in the list for the forecasts period, the length is 14\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2018_11.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting NCEP_CFSv2\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CanCM4i\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting GEM_NEMO\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting NASA_GEOSS2S\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M\n",
      "number of files in the archive: 27\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CanSIPSv2\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting JMA\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2019_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_test, X_index_test, GCM_records_test, GCM_coords_test = concat_GCMs(GCMs, var_name=var_X.upper(), period='forecasts', rpath=rpath, domain='ext_regional', standardize=False, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_coords_train['ECMWF']['lat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_coords_train['ECMWF']['lon'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a multi-index containing the lat and lon for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon = [GCM_coords_train['ECMWF']['lat'].data, GCM_coords_train['ECMWF']['lon'].data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### casts the training data into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=X_data_train, index=X_index_train, columns=latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the column containing the GCM names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:,'GCM'] = GCM_records_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### casts the testing data into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data=X_data_test, index=X_index_test, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[:,'GCM'] = GCM_records_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same as above, but for the standardized version of the training dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardized training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std = pd.DataFrame(data=X_data_train_std, index=X_index_train, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std.loc[:,'GCM'] = GCM_records_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the scalers ('trained' over the training set) to the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECMWF': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'UKMO': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'METEO_FRANCE': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'DWD': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'CMCC': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'NCEP_CFSv2': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'CanCM4i': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'GEM_NEMO': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'NASA_GEOSS2S': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'CanSIPSv2': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'JMA': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CMCC', 'CanCM4i', 'CanSIPSv2', 'DWD', 'ECMWF', 'GEM_NEMO', 'JMA',\n",
       "       'METEO_FRANCE', 'NASA_GEOSS2S', 'NCEP_CFSv2', 'UKMO'], dtype='<U12')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(GCM_records_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an emply numpy array with the same shape as X_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test_std = np.empty_like(X_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for GCM in GCMs: \n",
    "    idx_gcm = (GCM_records_test == GCM)\n",
    "    X_data_test_std[idx_gcm,:] = scalers_dict[GCM].transform(X_data_test[idx_gcm,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std = pd.DataFrame(data=X_data_test_std, index=X_index_test, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std.loc[:,'GCM'] = GCM_records_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pickle the standard scalers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### access to the means and standard deviations in the scalers are through the `mean_` and `scale_` attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict['ECMWF'].mean_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict['ECMWF'].scale_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./GCMs_StandardScalers.pickle', 'wb') as f:\n",
    "    pickle.dump(scalers_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fix the last column, from tuple `('GCM', '')` to just 'GCM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols[-1] = 'GCM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = cols\n",
    "df_train_std.columns = cols\n",
    "df_test.columns = cols\n",
    "df_test_std.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open \n",
    "# with open('./GCMs_StandardScalers.pickle', 'rb') as f: \n",
    "#     dict_scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 4930)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 4930)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_records_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_index_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TARGETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'TMEAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath_target = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'targets' / 'NZ_regions' / 'NZ_6_regions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for reg in ['NNI','WNI','ENI','NSI','WSI','ESI']: \n",
    "    target = pd.read_csv(dpath_target / target_var / reg / f'TS_NZ_region_{reg}_{target_var}_3_quantiles_anoms.csv', index_col=0, parse_dates=True)\n",
    "    target.columns = pd.MultiIndex.from_product([[reg],target.columns])\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.concat(targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">NNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ENI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean_N</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>18.278555</td>\n",
       "      <td>3</td>\n",
       "      <td>0.462528</td>\n",
       "      <td>16.051472</td>\n",
       "      <td>3</td>\n",
       "      <td>0.317965</td>\n",
       "      <td>16.732249</td>\n",
       "      <td>3</td>\n",
       "      <td>0.621540</td>\n",
       "      <td>13.811438</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.093327</td>\n",
       "      <td>11.848419</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.400334</td>\n",
       "      <td>13.728706</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>16.794408</td>\n",
       "      <td>2</td>\n",
       "      <td>0.227319</td>\n",
       "      <td>14.586906</td>\n",
       "      <td>3</td>\n",
       "      <td>0.248038</td>\n",
       "      <td>14.953599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299057</td>\n",
       "      <td>12.189450</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249176</td>\n",
       "      <td>10.589580</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.110858</td>\n",
       "      <td>12.033578</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.208919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>14.695903</td>\n",
       "      <td>2</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>12.522320</td>\n",
       "      <td>3</td>\n",
       "      <td>0.425773</td>\n",
       "      <td>12.716266</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314655</td>\n",
       "      <td>9.888897</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.215657</td>\n",
       "      <td>8.099501</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.202497</td>\n",
       "      <td>9.232035</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.470303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>12.093823</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>9.888909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117671</td>\n",
       "      <td>9.929897</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>7.198980</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300772</td>\n",
       "      <td>5.457298</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.197458</td>\n",
       "      <td>6.634168</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.254247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>10.290536</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.061355</td>\n",
       "      <td>8.182231</td>\n",
       "      <td>2</td>\n",
       "      <td>0.120974</td>\n",
       "      <td>8.208954</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.063564</td>\n",
       "      <td>5.534868</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.058724</td>\n",
       "      <td>3.763353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>4.916423</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NNI                        WNI                        ENI  \\\n",
       "              Tmean_N cat_3 anomalies    Tmean_N cat_3 anomalies    Tmean_N   \n",
       "time                                                                          \n",
       "1979-03-31  18.278555     3  0.462528  16.051472     3  0.317965  16.732249   \n",
       "1979-04-30  16.794408     2  0.227319  14.586906     3  0.248038  14.953599   \n",
       "1979-05-31  14.695903     2  0.282907  12.522320     3  0.425773  12.716266   \n",
       "1979-06-30  12.093823     2 -0.001099   9.888909     2  0.117671   9.929897   \n",
       "1979-07-31  10.290536     2 -0.061355   8.182231     2  0.120974   8.208954   \n",
       "\n",
       "                                  NSI                        WSI        \\\n",
       "           cat_3 anomalies    Tmean_N cat_3 anomalies    Tmean_N cat_3   \n",
       "time                                                                     \n",
       "1979-03-31     3  0.621540  13.811438     2 -0.093327  11.848419     1   \n",
       "1979-04-30     3  0.299057  12.189450     1 -0.249176  10.589580     2   \n",
       "1979-05-31     2  0.314655   9.888897     1 -0.215657   8.099501     1   \n",
       "1979-06-30     1 -0.065854   7.198980     1 -0.300772   5.457298     1   \n",
       "1979-07-31     2 -0.063564   5.534868     2 -0.058724   3.763353     2   \n",
       "\n",
       "                            ESI                  \n",
       "           anomalies    Tmean_N cat_3 anomalies  \n",
       "time                                             \n",
       "1979-03-31 -0.400334  13.728706     2 -0.222255  \n",
       "1979-04-30 -0.110858  12.033578     2 -0.208919  \n",
       "1979-05-31 -0.202497   9.232035     1 -0.470303  \n",
       "1979-06-30 -0.197458   6.634168     1 -0.254247  \n",
       "1979-07-31  0.085515   4.916423     2  0.112719  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies = targets.loc[:, (slice(None), [\"anomalies\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles = targets.loc[:, (slice(None), [\"cat_3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies.columns = target_anomalies.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles.columns = target_terciles.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI</th>\n",
       "      <th>WNI</th>\n",
       "      <th>ENI</th>\n",
       "      <th>NSI</th>\n",
       "      <th>WSI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI  WNI  ENI  NSI  WSI  ESI\n",
       "time                                    \n",
       "1979-03-31    3    3    3    2    1    2\n",
       "1979-04-30    2    3    3    1    2    2\n",
       "1979-05-31    2    3    2    1    1    1\n",
       "1979-06-30    2    2    1    1    1    1\n",
       "1979-07-31    2    2    2    2    2    2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_terciles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI</th>\n",
       "      <th>WNI</th>\n",
       "      <th>ENI</th>\n",
       "      <th>NSI</th>\n",
       "      <th>WSI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>0.462528</td>\n",
       "      <td>0.317965</td>\n",
       "      <td>0.621540</td>\n",
       "      <td>-0.093327</td>\n",
       "      <td>-0.400334</td>\n",
       "      <td>-0.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>0.227319</td>\n",
       "      <td>0.248038</td>\n",
       "      <td>0.299057</td>\n",
       "      <td>-0.249176</td>\n",
       "      <td>-0.110858</td>\n",
       "      <td>-0.208919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>0.282907</td>\n",
       "      <td>0.425773</td>\n",
       "      <td>0.314655</td>\n",
       "      <td>-0.215657</td>\n",
       "      <td>-0.202497</td>\n",
       "      <td>-0.470303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.117671</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>-0.300772</td>\n",
       "      <td>-0.197458</td>\n",
       "      <td>-0.254247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>-0.061355</td>\n",
       "      <td>0.120974</td>\n",
       "      <td>-0.063564</td>\n",
       "      <td>-0.058724</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.112719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NNI       WNI       ENI       NSI       WSI       ESI\n",
       "time                                                                  \n",
       "1979-03-31  0.462528  0.317965  0.621540 -0.093327 -0.400334 -0.222255\n",
       "1979-04-30  0.227319  0.248038  0.299057 -0.249176 -0.110858 -0.208919\n",
       "1979-05-31  0.282907  0.425773  0.314655 -0.215657 -0.202497 -0.470303\n",
       "1979-06-30 -0.001099  0.117671 -0.065854 -0.300772 -0.197458 -0.254247\n",
       "1979-07-31 -0.061355  0.120974 -0.063564 -0.058724  0.085515  0.112719"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename the columns for the target anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies.columns = [f\"{x}_anoms\" for x in target_anomalies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles.columns = [f\"{x}_cat3_categories\" for x in target_terciles.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI_cat3_categories</th>\n",
       "      <th>WNI_cat3_categories</th>\n",
       "      <th>ENI_cat3_categories</th>\n",
       "      <th>NSI_cat3_categories</th>\n",
       "      <th>WSI_cat3_categories</th>\n",
       "      <th>ESI_cat3_categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI_cat3_categories  WNI_cat3_categories  ENI_cat3_categories  \\\n",
       "time                                                                        \n",
       "1979-03-31                    3                    3                    3   \n",
       "1979-04-30                    2                    3                    3   \n",
       "1979-05-31                    2                    3                    2   \n",
       "1979-06-30                    2                    2                    1   \n",
       "1979-07-31                    2                    2                    2   \n",
       "\n",
       "            NSI_cat3_categories  WSI_cat3_categories  ESI_cat3_categories  \n",
       "time                                                                       \n",
       "1979-03-31                    2                    1                    2  \n",
       "1979-04-30                    1                    2                    2  \n",
       "1979-05-31                    1                    1                    1  \n",
       "1979-06-30                    1                    1                    1  \n",
       "1979-07-31                    2                    2                    2  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_terciles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI_anoms</th>\n",
       "      <th>WNI_anoms</th>\n",
       "      <th>ENI_anoms</th>\n",
       "      <th>NSI_anoms</th>\n",
       "      <th>WSI_anoms</th>\n",
       "      <th>ESI_anoms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>0.462528</td>\n",
       "      <td>0.317965</td>\n",
       "      <td>0.621540</td>\n",
       "      <td>-0.093327</td>\n",
       "      <td>-0.400334</td>\n",
       "      <td>-0.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>0.227319</td>\n",
       "      <td>0.248038</td>\n",
       "      <td>0.299057</td>\n",
       "      <td>-0.249176</td>\n",
       "      <td>-0.110858</td>\n",
       "      <td>-0.208919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>0.282907</td>\n",
       "      <td>0.425773</td>\n",
       "      <td>0.314655</td>\n",
       "      <td>-0.215657</td>\n",
       "      <td>-0.202497</td>\n",
       "      <td>-0.470303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.117671</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>-0.300772</td>\n",
       "      <td>-0.197458</td>\n",
       "      <td>-0.254247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>-0.061355</td>\n",
       "      <td>0.120974</td>\n",
       "      <td>-0.063564</td>\n",
       "      <td>-0.058724</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.112719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI_anoms  WNI_anoms  ENI_anoms  NSI_anoms  WSI_anoms  ESI_anoms\n",
       "time                                                                        \n",
       "1979-03-31   0.462528   0.317965   0.621540  -0.093327  -0.400334  -0.222255\n",
       "1979-04-30   0.227319   0.248038   0.299057  -0.249176  -0.110858  -0.208919\n",
       "1979-05-31   0.282907   0.425773   0.314655  -0.215657  -0.202497  -0.470303\n",
       "1979-06-30  -0.001099   0.117671  -0.065854  -0.300772  -0.197458  -0.254247\n",
       "1979-07-31  -0.061355   0.120974  -0.063564  -0.058724   0.085515   0.112719"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the GCM indices, which will have the effect of dupllicating the dates ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles_train = target_terciles.loc[X_index_train,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies_train = target_anomalies.loc[X_index_train,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test period. Note that there will be missing values in the the targets ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles_test = target_terciles.reindex(X_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies_test = target_anomalies.reindex(X_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now concatenate the GCM outputs, and the target terciles and anomalies, along the axis=1 (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'raw' anomalies (non-standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets = pd.concat([df_train, target_anomalies_train, target_terciles_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = pd.concat([df_test, target_anomalies_test, target_terciles_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCM anomalies standardized (per GCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets = pd.concat([df_train_std, target_anomalies_train, target_terciles_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets = pd.concat([df_test_std, target_anomalies_test, target_terciles_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'CSVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opath.exists(): \n",
    "    opath.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saves in CSVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'raw' GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.to_csv(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.to_csv(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardized GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.to_csv(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets = df_test_std_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.to_csv(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saves in PARQUET format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform the columns (multiindex) to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_columns = df_train_targets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_columns = [\"{} | {}\".format(*x) if isinstance(x, tuple) else x for x in tuple_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now saves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.to_parquet(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_training_set.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.to_parquet(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_test_set.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardized GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.to_parquet(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_training_set.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.to_parquet(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_test_set.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
