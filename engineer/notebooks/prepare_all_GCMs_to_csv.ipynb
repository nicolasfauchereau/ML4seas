{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first make sure we are in the right environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'climlab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not env in sys.executable:\n",
    "    print(f\"Please ensure this notebook is run in the {env} environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "# GCM variable \n",
    "var_X = 't2m'\n",
    "\n",
    "# target variable \n",
    "target_var = 'TMEAN'\n",
    "\n",
    "# target type (anomalies ('anomalies') or terciles categories ('cat_3'))\n",
    "target_type = 'cat_3'\n",
    "\n",
    "# step: 3 = one month lead time on the next 3 months aggregated statistic\n",
    "step = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load external modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = pathlib.Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../ml4seas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xesmf is not installed, using method `interp_like` for interpolation\n"
     ]
    }
   ],
   "source": [
    "from utils import set_root_dir\n",
    "from GCM import get_GCM_outputs, shift_dset_time, concat_GCMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### domain definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_def = {}\n",
    "domain_def['local'] = [150, 200, -50, -10]\n",
    "domain_def['regional'] = [90, 300, -65, 50]\n",
    "domain_def['ext_regional'] = [70, 300, -70, 60]\n",
    "# domain_def['ext_regional'] = [50, 300, -75, 60]\n",
    "domain_def['global'] = [0, 360, -70, 70]\n",
    "domain_def['tropics'] = [0, 360, -40, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['local', 'regional', 'ext_regional', 'global', 'tropics'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_def.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domains = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_domains: \n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.feature as cfeature\n",
    "    for k in domain_def.keys(): \n",
    "        f, ax = plt.subplots(figsize=(10,8), subplot_kw={'projection':ccrs.PlateCarree(central_longitude=180)})\n",
    "        ax.set_extent(domain_def[k], crs=ccrs.PlateCarree())\n",
    "        ax.coastlines(resolution='50m')\n",
    "#         ax.add_feature(cfeature.LAND)\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "#         ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "        f.savefig(f'../../../figures/domain_{k}.png', dpi=200, bbox_inches='tight')  \n",
    "        plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the root path for the `data` folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCMs = ['ECMWF', 'UKMO', 'METEO_FRANCE', 'DWD', 'CMCC', 'NCEP_CFSv2', 'CanCM4i', 'GEM_NEMO', 'NASA_GEOSS2S', 'CanSIPSv2', 'JMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCM providers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCM_provider = {}\n",
    "GCM_provider['ECMWF'] = 'CDS'\n",
    "GCM_provider['UKMO'] = 'CDS'\n",
    "GCM_provider['METEO_FRANCE'] = 'CDS'\n",
    "GCM_provider['DWD'] = 'CDS'\n",
    "GCM_provider['CMCC'] = 'CDS'\n",
    "\n",
    "GCM_provider['NCEP_CFSv2'] = 'IRI'\n",
    "GCM_provider['CanCM4i'] = 'IRI'\n",
    "GCM_provider['GEM_NEMO'] = 'IRI'\n",
    "GCM_provider['NASA_GEOSS2S'] = 'IRI'\n",
    "GCM_provider['CanSIPSv2'] = 'IRI'\n",
    "\n",
    "GCM_provider['JMA'] = 'JMA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCM paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCM_path = {}\n",
    "GCM_path['ECMWF'] = 'gdata'\n",
    "GCM_path['UKMO'] = 'gdata'\n",
    "GCM_path['METEO_FRANCE'] = 'gdata'\n",
    "GCM_path['DWD'] = 'gdata'\n",
    "GCM_path['CMCC'] = 'local'\n",
    "\n",
    "GCM_path['NCEP_CFSv2'] = 'gdata'\n",
    "GCM_path['CanCM4i'] = 'local'\n",
    "GCM_path['GEM_NEMO'] = 'gdata'\n",
    "GCM_path['NASA_GEOSS2S'] = 'gdata'\n",
    "GCM_path['CanSIPSv2'] = 'gdata'\n",
    "\n",
    "GCM_path['JMA'] = 'gdata'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check first if there are no issues with each of the GCMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind_GCM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_ind_GCM: \n",
    "    coords_dict = {}\n",
    "    for GCM in GCMs: \n",
    "        rpath = set_root_dir(GCM_path[GCM])\n",
    "        provider = GCM_provider[GCM]\n",
    "        print('-------------------------------------------------------------------------------')\n",
    "        print(f\"\\n\\nGCM {GCM}\\nrpath set to {str(rpath)}\")\n",
    "        print(f\"provider {provider}\")\n",
    "        GCM_dset, coords = get_GCM_outputs(provider=provider, GCM=GCM, var_name=var_X.upper(), rpath=rpath, domain=domain_def['ext_regional'], flatten=False)\n",
    "        coords_dict[GCM] = coords\n",
    "        if len(coords['time']) == len(pd.date_range(start=GCM_dset.time.to_index()[0], end=GCM_dset.time.to_index()[-1], freq='MS')): \n",
    "            print(f'time coordinate matching for {GCM}')\n",
    "        else: \n",
    "            print(f'issue with time coordinate not matching expected length for {GCM}')\n",
    "        GCM_dset.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems all OK, now concatenate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M\n",
      "number of files in the archive: 287\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_1993_02.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/CDS/CMCC/T2M\n",
      "number of files in the archive: 288\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting NCEP_CFSv2\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M\n",
      "number of files in the archive: 420\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_1982_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CanCM4i\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M\n",
      "number of files in the archive: 432\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/hindcasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting GEM_NEMO\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M\n",
      "number of files in the archive: 432\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting NASA_GEOSS2S\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M\n",
      "number of files in the archive: 431\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_1981_02.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CanSIPSv2\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M\n",
      "number of files in the archive: 432\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_1981_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting JMA\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M\n",
      "number of files in the archive: 456\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_1979_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2016_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_train, X_data_train_std, X_index_train, GCM_records_train, GCM_coords_train, scalers_dict = concat_GCMs(GCMs, var_name=var_X.upper(), period='hindcasts', rpath=GCM_path, domain='ext_regional', standardize=True, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now get the forecasts from the local drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/T2M/ECMWF_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M\n",
      "number of files in the archive: 28\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2017_09.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/T2M/UKMO_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/T2M/METEO_FRANCE_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/T2M/DWD_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M\n",
      "number of files in the archive: 14\n",
      "Something wrong with the number of files in the list for the forecasts period, the length is 14\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2018_11.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/T2M/CMCC_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting NCEP_CFSv2\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NCEP_CFSv2/T2M/NCEP_CFSv2_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CanCM4i\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanCM4i/T2M/CanCM4i_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "WARNING: the length of the time index is 29, expected 36\n",
      "\n",
      "months missing for year 2017: \n",
      "months missing for year 2018: \n",
      "months missing for year 2019: 1, 2, 3, 4, 5, 6, 7\n",
      "\n",
      "-----------------   getting GEM_NEMO\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/GEM_NEMO/T2M/GEM_NEMO_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "WARNING: the length of the time index is 29, expected 36\n",
      "\n",
      "months missing for year 2017: \n",
      "months missing for year 2018: \n",
      "months missing for year 2019: 1, 2, 3, 4, 5, 6, 7\n",
      "\n",
      "-----------------   getting NASA_GEOSS2S\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M\n",
      "number of files in the archive: 27\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/NASA_GEOSS2S/T2M/NASA_GEOSS2S_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "WARNING: the length of the time index is 27, expected 36\n",
      "\n",
      "months missing for year 2017: 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
      "months missing for year 2018: \n",
      "months missing for year 2019: \n",
      "\n",
      "-----------------   getting CanSIPSv2\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M\n",
      "number of files in the archive: 29\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/IRI/CanSIPSv2/T2M/CanSIPSv2_T2M_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "WARNING: the length of the time index is 29, expected 36\n",
      "\n",
      "months missing for year 2017: \n",
      "months missing for year 2018: \n",
      "months missing for year 2019: 1, 2, 3, 4, 5, 6, 7\n",
      "\n",
      "-----------------   getting JMA\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/JMA/JMA/T2M/JMA_T2M_seasonal_anomalies_2019_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_test, X_index_test, GCM_records_test, GCM_coords_test = concat_GCMs(GCMs, var_name=var_X.upper(), period='forecasts', rpath=rpath, domain='ext_regional', standardize=False, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_coords_train['ECMWF']['lat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_coords_train['ECMWF']['lon'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a multi-index containing the lat and lon for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon = [GCM_coords_train['ECMWF']['lat'].data, GCM_coords_train['ECMWF']['lon'].data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### casts the training data into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=X_data_train, index=X_index_train, columns=latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the column containing the GCM names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:,'GCM'] = GCM_records_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### casts the testing data into a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data=X_data_test, index=X_index_test, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[:,'GCM'] = GCM_records_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same as above, but for the standardized version of the training dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardized training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std = pd.DataFrame(data=X_data_train_std, index=X_index_train, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std.loc[:,'GCM'] = GCM_records_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the scalers ('trained' over the training set) to the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECMWF': StandardScaler(),\n",
       " 'UKMO': StandardScaler(),\n",
       " 'METEO_FRANCE': StandardScaler(),\n",
       " 'DWD': StandardScaler(),\n",
       " 'CMCC': StandardScaler(),\n",
       " 'NCEP_CFSv2': StandardScaler(),\n",
       " 'CanCM4i': StandardScaler(),\n",
       " 'GEM_NEMO': StandardScaler(),\n",
       " 'NASA_GEOSS2S': StandardScaler(),\n",
       " 'CanSIPSv2': StandardScaler(),\n",
       " 'JMA': StandardScaler()}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CMCC', 'CanCM4i', 'CanSIPSv2', 'DWD', 'ECMWF', 'GEM_NEMO', 'JMA',\n",
       "       'METEO_FRANCE', 'NASA_GEOSS2S', 'NCEP_CFSv2', 'UKMO'], dtype='<U12')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(GCM_records_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an emply numpy array with the same shape as X_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test_std = np.empty_like(X_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for GCM in GCMs: \n",
    "    idx_gcm = (GCM_records_test == GCM)\n",
    "    X_data_test_std[idx_gcm,:] = scalers_dict[GCM].transform(X_data_test[idx_gcm,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std = pd.DataFrame(data=X_data_test_std, index=X_index_test, columns=latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std.loc[:,'GCM'] = GCM_records_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pickle the standard scalers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### access to the means and standard deviations in the scalers are through the `mean_` and `scale_` attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict['ECMWF'].mean_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict['ECMWF'].scale_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'./GCMs_StandardScalers_{var_X}.pickle', 'wb') as f:\n",
    "    pickle.dump(scalers_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open \n",
    "# with open(f'./GCMs_StandardScalers_{var_X}.pickle', 'rb') as f: \n",
    "#     dict_scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fix the last column, from tuple `('GCM', '')` to just 'GCM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols[-1] = 'GCM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = cols\n",
    "df_train_std.columns = cols\n",
    "df_test.columns = cols\n",
    "df_test_std.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 4930)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 4930)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCM_records_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TARGETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath_target = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'targets' / 'NZ_regions' / 'NZ_6_regions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for reg in ['NNI','WNI','ENI','NSI','WSI','ESI']: \n",
    "    target = pd.read_csv(dpath_target / target_var / reg / f'TS_NZ_region_{reg}_{target_var}_3_quantiles_anoms.csv', index_col=0, parse_dates=True)\n",
    "    target.columns = pd.MultiIndex.from_product([[reg],target.columns])\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.concat(targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">NNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ENI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>18.334898</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465166</td>\n",
       "      <td>16.082092</td>\n",
       "      <td>3</td>\n",
       "      <td>0.304931</td>\n",
       "      <td>16.679982</td>\n",
       "      <td>3</td>\n",
       "      <td>0.502118</td>\n",
       "      <td>13.732586</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.217639</td>\n",
       "      <td>11.877792</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.564083</td>\n",
       "      <td>13.713081</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.283684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>16.843733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>14.603668</td>\n",
       "      <td>2</td>\n",
       "      <td>0.216870</td>\n",
       "      <td>14.917330</td>\n",
       "      <td>2</td>\n",
       "      <td>0.189383</td>\n",
       "      <td>12.033210</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.446051</td>\n",
       "      <td>10.507519</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349023</td>\n",
       "      <td>11.984851</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.320514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>14.747330</td>\n",
       "      <td>2</td>\n",
       "      <td>0.276076</td>\n",
       "      <td>12.512171</td>\n",
       "      <td>2</td>\n",
       "      <td>0.376263</td>\n",
       "      <td>12.630520</td>\n",
       "      <td>2</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>9.707791</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.433259</td>\n",
       "      <td>7.936031</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.455407</td>\n",
       "      <td>9.166171</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.602066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>12.155292</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>9.869630</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>9.890404</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.153712</td>\n",
       "      <td>7.196983</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.372330</td>\n",
       "      <td>5.447644</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.275615</td>\n",
       "      <td>6.650281</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.318733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>10.388794</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>8.182760</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123649</td>\n",
       "      <td>8.139223</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.148967</td>\n",
       "      <td>5.561078</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.077330</td>\n",
       "      <td>3.780598</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103711</td>\n",
       "      <td>4.945369</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NNI                        WNI                        ENI  \\\n",
       "                Tmean cat_3 anomalies      Tmean cat_3 anomalies      Tmean   \n",
       "time                                                                          \n",
       "1979-03-31  18.334898     3  0.465166  16.082092     3  0.304931  16.679982   \n",
       "1979-04-30  16.843733     2  0.216447  14.603668     2  0.216870  14.917330   \n",
       "1979-05-31  14.747330     2  0.276076  12.512171     2  0.376263  12.630520   \n",
       "1979-06-30  12.155292     2  0.014663   9.869630     2  0.075591   9.890404   \n",
       "1979-07-31  10.388794     2  0.012815   8.182760     2  0.123649   8.139223   \n",
       "\n",
       "                                  NSI                        WSI        \\\n",
       "           cat_3 anomalies      Tmean cat_3 anomalies      Tmean cat_3   \n",
       "time                                                                     \n",
       "1979-03-31     3  0.502118  13.732586     2 -0.217639  11.877792     1   \n",
       "1979-04-30     2  0.189383  12.033210     1 -0.446051  10.507519     1   \n",
       "1979-05-31     2  0.167765   9.707791     1 -0.433259   7.936031     1   \n",
       "1979-06-30     1 -0.153712   7.196983     1 -0.372330   5.447644     1   \n",
       "1979-07-31     2 -0.148967   5.561078     2 -0.077330   3.780598     2   \n",
       "\n",
       "                            ESI                  \n",
       "           anomalies      Tmean cat_3 anomalies  \n",
       "time                                             \n",
       "1979-03-31 -0.564083  13.713081     2 -0.283684  \n",
       "1979-04-30 -0.349023  11.984851     2 -0.320514  \n",
       "1979-05-31 -0.455407   9.166171     1 -0.602066  \n",
       "1979-06-30 -0.275615   6.650281     1 -0.318733  \n",
       "1979-07-31  0.103711   4.945369     2  0.091800  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies = targets.loc[:, (slice(None), [\"anomalies\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles = targets.loc[:, (slice(None), [\"cat_3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies.columns = target_anomalies.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles.columns = target_terciles.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI</th>\n",
       "      <th>WNI</th>\n",
       "      <th>ENI</th>\n",
       "      <th>NSI</th>\n",
       "      <th>WSI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI  WNI  ENI  NSI  WSI  ESI\n",
       "time                                    \n",
       "1979-03-31    3    3    3    2    1    2\n",
       "1979-04-30    2    2    2    1    1    2\n",
       "1979-05-31    2    2    2    1    1    1\n",
       "1979-06-30    2    2    1    1    1    1\n",
       "1979-07-31    2    2    2    2    2    2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_terciles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI</th>\n",
       "      <th>WNI</th>\n",
       "      <th>ENI</th>\n",
       "      <th>NSI</th>\n",
       "      <th>WSI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>0.465166</td>\n",
       "      <td>0.304931</td>\n",
       "      <td>0.502118</td>\n",
       "      <td>-0.217639</td>\n",
       "      <td>-0.564083</td>\n",
       "      <td>-0.283684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.216870</td>\n",
       "      <td>0.189383</td>\n",
       "      <td>-0.446051</td>\n",
       "      <td>-0.349023</td>\n",
       "      <td>-0.320514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>0.276076</td>\n",
       "      <td>0.376263</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>-0.433259</td>\n",
       "      <td>-0.455407</td>\n",
       "      <td>-0.602066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>-0.153712</td>\n",
       "      <td>-0.372330</td>\n",
       "      <td>-0.275615</td>\n",
       "      <td>-0.318733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.123649</td>\n",
       "      <td>-0.148967</td>\n",
       "      <td>-0.077330</td>\n",
       "      <td>0.103711</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NNI       WNI       ENI       NSI       WSI       ESI\n",
       "time                                                                  \n",
       "1979-03-31  0.465166  0.304931  0.502118 -0.217639 -0.564083 -0.283684\n",
       "1979-04-30  0.216447  0.216870  0.189383 -0.446051 -0.349023 -0.320514\n",
       "1979-05-31  0.276076  0.376263  0.167765 -0.433259 -0.455407 -0.602066\n",
       "1979-06-30  0.014663  0.075591 -0.153712 -0.372330 -0.275615 -0.318733\n",
       "1979-07-31  0.012815  0.123649 -0.148967 -0.077330  0.103711  0.091800"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename the columns for the target anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies.columns = [f\"{x}_anoms\" for x in target_anomalies.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles.columns = [f\"{x}_cat3_categories\" for x in target_terciles.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI_cat3_categories</th>\n",
       "      <th>WNI_cat3_categories</th>\n",
       "      <th>ENI_cat3_categories</th>\n",
       "      <th>NSI_cat3_categories</th>\n",
       "      <th>WSI_cat3_categories</th>\n",
       "      <th>ESI_cat3_categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI_cat3_categories  WNI_cat3_categories  ENI_cat3_categories  \\\n",
       "time                                                                        \n",
       "1979-03-31                    3                    3                    3   \n",
       "1979-04-30                    2                    2                    2   \n",
       "1979-05-31                    2                    2                    2   \n",
       "1979-06-30                    2                    2                    1   \n",
       "1979-07-31                    2                    2                    2   \n",
       "\n",
       "            NSI_cat3_categories  WSI_cat3_categories  ESI_cat3_categories  \n",
       "time                                                                       \n",
       "1979-03-31                    2                    1                    2  \n",
       "1979-04-30                    1                    1                    2  \n",
       "1979-05-31                    1                    1                    1  \n",
       "1979-06-30                    1                    1                    1  \n",
       "1979-07-31                    2                    2                    2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_terciles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNI_anoms</th>\n",
       "      <th>WNI_anoms</th>\n",
       "      <th>ENI_anoms</th>\n",
       "      <th>NSI_anoms</th>\n",
       "      <th>WSI_anoms</th>\n",
       "      <th>ESI_anoms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>0.465166</td>\n",
       "      <td>0.304931</td>\n",
       "      <td>0.502118</td>\n",
       "      <td>-0.217639</td>\n",
       "      <td>-0.564083</td>\n",
       "      <td>-0.283684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.216870</td>\n",
       "      <td>0.189383</td>\n",
       "      <td>-0.446051</td>\n",
       "      <td>-0.349023</td>\n",
       "      <td>-0.320514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>0.276076</td>\n",
       "      <td>0.376263</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>-0.433259</td>\n",
       "      <td>-0.455407</td>\n",
       "      <td>-0.602066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>-0.153712</td>\n",
       "      <td>-0.372330</td>\n",
       "      <td>-0.275615</td>\n",
       "      <td>-0.318733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.123649</td>\n",
       "      <td>-0.148967</td>\n",
       "      <td>-0.077330</td>\n",
       "      <td>0.103711</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NNI_anoms  WNI_anoms  ENI_anoms  NSI_anoms  WSI_anoms  ESI_anoms\n",
       "time                                                                        \n",
       "1979-03-31   0.465166   0.304931   0.502118  -0.217639  -0.564083  -0.283684\n",
       "1979-04-30   0.216447   0.216870   0.189383  -0.446051  -0.349023  -0.320514\n",
       "1979-05-31   0.276076   0.376263   0.167765  -0.433259  -0.455407  -0.602066\n",
       "1979-06-30   0.014663   0.075591  -0.153712  -0.372330  -0.275615  -0.318733\n",
       "1979-07-31   0.012815   0.123649  -0.148967  -0.077330   0.103711   0.091800"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the GCM indices, which will have the effect of dupllicating the dates ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles_train = target_terciles.reindex(X_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies_train = target_anomalies.reindex(X_index_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test period. Note that there will be missing values in the the targets ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles_test = target_terciles.reindex(X_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomalies_test = target_anomalies.reindex(X_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now concatenate the GCM outputs, and the target terciles and anomalies, along the axis=1 (column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'raw' anomalies (non-standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets = pd.concat([df_train, target_anomalies_train, target_terciles_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = pd.concat([df_test, target_anomalies_test, target_terciles_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCM anomalies standardized (per GCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets = pd.concat([df_train_std, target_anomalies_train, target_terciles_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets = pd.concat([df_test_std, target_anomalies_test, target_terciles_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'CSVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opath.exists(): \n",
    "    opath.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### truncate to avoid data leakage, the last season of the training should be NDJ 2016 - 2017, and the first season in the test set at the earliest FMA 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ltr = []\n",
    "for gcm in df_train_targets.loc[:,'GCM'].unique():\n",
    "#     print(gcm)\n",
    "    df = df_train_targets.loc[df_train_targets.loc[:,'GCM'] == gcm,:]\n",
    "    df = df.iloc[:-2,:]\n",
    "    print(df.index[-1])\n",
    "    ltr.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 4942)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets = pd.concat(ltr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4020, 4942)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n",
      "2017-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ltr = []\n",
    "for gcm in df_train_std_targets.loc[:,'GCM'].unique():\n",
    "#     print(gcm)\n",
    "    df = df_train_std_targets.loc[df_train_std_targets.loc[:,'GCM'] == gcm,:]\n",
    "    df = df.iloc[:-2,:]\n",
    "    print(df.index[-1])\n",
    "    ltr.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4042, 4942)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_std_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets = pd.concat(ltr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4020, 4942)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_std_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saves in CSVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'raw' GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets = df_train_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.to_csv(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.to_csv(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardized GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets = df_train_std_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.to_csv(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets = df_test_std_targets.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.to_csv(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TMEAN'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t2m'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saves in PARQUET format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform the columns (multiindex) to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_columns = df_train_targets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_columns = [\"{} | {}\".format(*x) if isinstance(x, tuple) else x for x in tuple_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.columns = str_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now saves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.to_parquet(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_training_set.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets.to_parquet(opath / f'GCMs_and_targets_cat3_and_anomalies_{target_var}_test_set.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardized GCM anomalies version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_std_targets.to_parquet(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_training_set.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_std_targets.to_parquet(opath / f'GCMs_std_and_targets_cat3_and_anomalies_{target_var}_test_set.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
