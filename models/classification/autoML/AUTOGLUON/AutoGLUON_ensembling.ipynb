{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGLUON experiments using the formatted CSV files as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the environment first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "GCM = 'ECMWF'\n",
    "var_name = 'RAIN'\n",
    "target_type = 'cat3_categories'\n",
    "region_name = 'NNI'\n",
    "skpca = True \n",
    "standardized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load external modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from shutil import copytree, rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = pathlib.Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import autogluon, tabular prediction, see [https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html](https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../../ml4seas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCM import prepare_data_CSV_to_AUTOML\n",
    "from evaluation import calc_accuracy_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'CSVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_RAIN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_TMEAN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_TMEAN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_RAIN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_RAIN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_TMEAN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_TMEAN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_RAIN_training_set.csv')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dpath.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if standardized: \n",
    "    train_data = pd.read_csv(dpath / f'GCMs_std_and_targets_cat3_and_anomalies_{var_name}_training_set.csv', index_col=0, parse_dates=True) \n",
    "    test_data = pd.read_csv(dpath / f'GCMs_std_and_targets_cat3_and_anomalies_{var_name}_test_set.csv', index_col=0, parse_dates=True)\n",
    "else: \n",
    "    train_data = pd.read_csv(dpath / f'GCMs_and_targets_cat3_and_anomalies_{var_name}_training_set.csv', index_col=0, parse_dates=True) \n",
    "    test_data = pd.read_csv(dpath / f'GCMs_and_targets_cat3_and_anomalies_{var_name}_test_set.csv', index_col=0, parse_dates=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "train_data, GCMs_name_train, _, _ = prepare_data_CSV_to_AUTOML(train_data, GCM=GCM, region_name=region_name, target_type=target_type, scaling=False, doPCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, GCMs_name_test, _, _ = prepare_data_CSV_to_AUTOML(test_data, GCM=GCM, region_name=region_name, target_type=target_type, scaling=False, doPCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4930)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratified k-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the percentage of variance to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_variance = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### root path for saving the parameters of all the AUTOGLUON experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = pathlib.Path('./saved_models/AUTOGLUON_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = saved_models.joinpath(f'./autogluon_exp_SKPCA_{GCM}_pred_{region_name}_reg_{var_name}_targetvar_{target_type}_target_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opath.exists(): \n",
    "    opath.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checks on the shape and content of the training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNI_cat3_categories\n"
     ]
    }
   ],
   "source": [
    "target_col = f\"{region_name}_{target_type}\"; print(target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialise a stratified K-Fold object, which will return train and test indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10).split(train_data.drop(labels=[target_col],axis=1).values, train_data.loc[:,target_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = []\n",
    "# y_preds = []\n",
    "# leader_board = []\n",
    "# perfs = []\n",
    "\n",
    "# for k, (train, test) in enumerate(kfold):\n",
    "    \n",
    "#     X_train = train_data.drop(labels=[target_col],axis=1).iloc[train,:]\n",
    "    \n",
    "#     y_train = train_data.loc[:,target_col].iloc[train,]\n",
    "    \n",
    "#     X_test = train_data.drop(labels=[target_col],axis=1).iloc[test,:]\n",
    "    \n",
    "#     y_test = X_df.loc[:,target_col].iloc[test,]\n",
    "    \n",
    "#     df_train = X_train.copy() \n",
    "#     df_train.loc[:, target_col] = y_train\n",
    "    \n",
    "#     df_test = X_test.copy() \n",
    "#     df_test.loc[:,target_col] = y_test\n",
    "    \n",
    "    \n",
    "#      # fit the task predictor on the training set DataFrame \n",
    "#     predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True, output_directory=opath)\n",
    "    \n",
    "#     # predict the probabilities for each class from the test set features DataFrame (droping the target values column)\n",
    "#     # y_pred_proba = predictor.predict_proba(df_test.drop(labels=[region_name],axis=1))\n",
    "    \n",
    "#     # predict the class value itself\n",
    "#     y_pred = predictor.predict(df_test.drop(labels=[target_col],axis=1))\n",
    "    \n",
    "#     # records the probabilities for the classes on the test set \n",
    "#     y_preds.append(y_pred)\n",
    "    \n",
    "#     # get the leaderboard DataFrame \n",
    "#     d = predictor.leaderboard(silent=True)\n",
    "    \n",
    "#     # records the leaderboard DataFrame \n",
    "#     leader_board.append(d)\n",
    "    \n",
    "#     perfs.append(predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True, silent=True))\n",
    "    \n",
    "#     print(f\"EXITING FOLD {k} ---- \")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 104\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 3. 2.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTERING FOLD 0 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 258 data points with 103 features\n",
      "Original Features:\n",
      "\tfloat features: 103\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 103\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return _load(spec)\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4961\t = Validation accuracy score\n",
      "\t2.74s\t = Training runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4341\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4806\t = Validation accuracy score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.5039\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.4884\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5271\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.531\t = Validation accuracy score\n",
      "\t2.27s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.562\t = Validation accuracy score\n",
      "\t12.18s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5\t = Validation accuracy score\n",
      "\t15.25s\t = Training runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.5078\t = Validation accuracy score\n",
      "\t7.21s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5659\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 53.65s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 109\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 0 ---- \n",
      "ENTERING FOLD 1 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 258 data points with 108 features\n",
      "Original Features:\n",
      "\tfloat features: 108\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 108\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4729\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4651\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4341\t = Validation accuracy score\n",
      "\t2.15s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4419\t = Validation accuracy score\n",
      "\t2.21s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.4535\t = Validation accuracy score\n",
      "\t0.24s\t = Training runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5155\t = Validation accuracy score\n",
      "\t0.28s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.4612\t = Validation accuracy score\n",
      "\t1.85s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.4961\t = Validation accuracy score\n",
      "\t10.52s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.4845\t = Validation accuracy score\n",
      "\t13.28s\t = Training runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4419\t = Validation accuracy score\n",
      "\t6.6s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5581\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 48.84s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 108\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 1 ---- \n",
      "ENTERING FOLD 2 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 258 data points with 107 features\n",
      "Original Features:\n",
      "\tfloat features: 107\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 107\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4922\t = Validation accuracy score\n",
      "\t2.73s\t = Training runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4961\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.5078\t = Validation accuracy score\n",
      "\t2.17s\t = Training runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4845\t = Validation accuracy score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.4884\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5543\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.5039\t = Validation accuracy score\n",
      "\t2.07s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.5465\t = Validation accuracy score\n",
      "\t11.44s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.531\t = Validation accuracy score\n",
      "\t13.8s\t = Training runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4884\t = Validation accuracy score\n",
      "\t7.68s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5853\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 51.76s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 103\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 2 ---- \n",
      "ENTERING FOLD 3 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 258 data points with 102 features\n",
      "Original Features:\n",
      "\tfloat features: 102\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 102\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.5388\t = Validation accuracy score\n",
      "\t2.76s\t = Training runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5233\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4961\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.5349\t = Validation accuracy score\n",
      "\t2.19s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5349\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5814\t = Validation accuracy score\n",
      "\t0.3s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.5969\t = Validation accuracy score\n",
      "\t1.87s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.562\t = Validation accuracy score\n",
      "\t10.5s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5465\t = Validation accuracy score\n",
      "\t12.39s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.562\t = Validation accuracy score\n",
      "\t8.49s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6047\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 50.04s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 104\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 3 ---- \n",
      "ENTERING FOLD 4 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 103 features\n",
      "Original Features:\n",
      "\tfloat features: 103\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 103\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4385\t = Validation accuracy score\n",
      "\t2.68s\t = Training runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4462\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4154\t = Validation accuracy score\n",
      "\t2.33s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4231\t = Validation accuracy score\n",
      "\t2.19s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5615\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5885\t = Validation accuracy score\n",
      "\t0.22s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.5269\t = Validation accuracy score\n",
      "\t2.0s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.4962\t = Validation accuracy score\n",
      "\t10.8s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.4962\t = Validation accuracy score\n",
      "\t22.4s\t = Training runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.45\t = Validation accuracy score\n",
      "\t7.83s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6038\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 59.49s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 104\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 4 ---- \n",
      "ENTERING FOLD 5 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 103 features\n",
      "Original Features:\n",
      "\tfloat features: 103\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 103\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4538\t = Validation accuracy score\n",
      "\t2.79s\t = Training runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4538\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4538\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4692\t = Validation accuracy score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5423\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5692\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.5038\t = Validation accuracy score\n",
      "\t1.97s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.5423\t = Validation accuracy score\n",
      "\t13.38s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5308\t = Validation accuracy score\n",
      "\t21.08s\t = Training runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4923\t = Validation accuracy score\n",
      "\t6.93s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.14s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 106\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 5 ---- \n",
      "ENTERING FOLD 6 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 105 features\n",
      "Original Features:\n",
      "\tfloat features: 105\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 105\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4462\t = Validation accuracy score\n",
      "\t2.78s\t = Training runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4462\t = Validation accuracy score\n",
      "\t2.73s\t = Training runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4731\t = Validation accuracy score\n",
      "\t2.19s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4462\t = Validation accuracy score\n",
      "\t2.19s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5231\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.55\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.45\t = Validation accuracy score\n",
      "\t2.07s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.4923\t = Validation accuracy score\n",
      "\t12.77s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5\t = Validation accuracy score\n",
      "\t19.32s\t = Training runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4538\t = Validation accuracy score\n",
      "\t6.61s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5808\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 57.46s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 106\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 6 ---- \n",
      "ENTERING FOLD 7 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 105 features\n",
      "Original Features:\n",
      "\tfloat features: 105\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 105\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4038\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.3846\t = Validation accuracy score\n",
      "\t2.72s\t = Training runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.3846\t = Validation accuracy score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4154\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.4846\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5154\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.45\t = Validation accuracy score\n",
      "\t1.92s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.4923\t = Validation accuracy score\n",
      "\t10.17s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.4423\t = Validation accuracy score\n",
      "\t7.58s\t = Training runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4538\t = Validation accuracy score\n",
      "\t6.36s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5269\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 42.95s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 106\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 7 ---- \n",
      "ENTERING FOLD 8 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 105 features\n",
      "Original Features:\n",
      "\tfloat features: 105\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 105\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4423\t = Validation accuracy score\n",
      "\t2.74s\t = Training runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4115\t = Validation accuracy score\n",
      "\t2.68s\t = Training runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4385\t = Validation accuracy score\n",
      "\t2.31s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4385\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5115\t = Validation accuracy score\n",
      "\t0.27s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5308\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.4885\t = Validation accuracy score\n",
      "\t1.85s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.5462\t = Validation accuracy score\n",
      "\t17.37s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5154\t = Validation accuracy score\n",
      "\t18.6s\t = Training runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4731\t = Validation accuracy score\n",
      "\t9.5s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.55\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 64.3s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 107\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 8 ---- \n",
      "ENTERING FOLD 9 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 106 features\n",
      "Original Features:\n",
      "\tfloat features: 106\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 106\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.4769\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4885\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4769\t = Validation accuracy score\n",
      "\t2.2s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4462\t = Validation accuracy score\n",
      "\t2.19s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5231\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5577\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.55\t = Validation accuracy score\n",
      "\t1.73s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.5423\t = Validation accuracy score\n",
      "\t16.11s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5077\t = Validation accuracy score\n",
      "\t19.73s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.5423\t = Validation accuracy score\n",
      "\t8.81s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 63.09s ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 9 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_indices = []\n",
    "y_preds = []\n",
    "leader_board = []\n",
    "perfs = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    \n",
    "    print(f\"ENTERING FOLD {k} ---- \")\n",
    "    \n",
    "    # saves the test indices\n",
    "    test_indices.append(test)\n",
    "    \n",
    "    # get the numpy array containing the training set initial features (grid points)\n",
    "    X_train = train_data.drop(labels=[target_col],axis=1).values[train]\n",
    "    \n",
    "    # get the numpy array containing the training set target values (y)\n",
    "    y_train =  train_data.loc[:,target_col].values[train]\n",
    "    \n",
    "    # get the numpy array containing the test set initial features (grid points)\n",
    "    X_test = train_data.drop(labels=[target_col],axis=1).values[test]\n",
    "    \n",
    "    # get the numpy array containing the test set target values (y)\n",
    "    y_test = train_data.loc[:,target_col].values[test]\n",
    "    \n",
    "    # -----------\n",
    "    # standardize \n",
    "    \n",
    "    # initialise the scaler (standard scaler)\n",
    "    scaler = StandardScaler() \n",
    "    \n",
    "    # fit on the training set features array, and transform to obtain standardized values\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # apply the transformation on the test set initial features \n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Principal Component Analysis \n",
    "    \n",
    "    # instantiate the pca class, with percent of variance to keep  \n",
    "    \n",
    "    skpca = pca.PCA(n_components=percent_variance)\n",
    "    \n",
    "    # fit on the training initial (standardized) fedatures array, and transform to obtain the PCs\n",
    "    X_train_PC = skpca.fit_transform(X_train_std)\n",
    "    \n",
    "    # apply the transformation on the test set standardized features \n",
    "    X_test_PC = skpca.transform(X_test_std)\n",
    "    \n",
    "    # assign the training set PCs to a DataFrame \n",
    "    df_train = pd.DataFrame(X_train_PC) \n",
    "    \n",
    "    # add the target values to the training DataFrame \n",
    "    df_train.loc[:,target_col] = y_train\n",
    "    \n",
    "    # assign the test set Pcs to a DataFrame \n",
    "    df_test = pd.DataFrame(X_test_PC) \n",
    "    \n",
    "    # add the target values to the test DataFrame\n",
    "    df_test.loc[:,target_col] = y_test\n",
    "    \n",
    "    # fit the task predictor on the training set DataFrame \n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True, output_directory=opath)\n",
    "    \n",
    "    # predict the probabilities for each class from the test set features DataFrame (droping the target values column)\n",
    "#     y_pred_proba = predictor.predict_proba(df_test.drop(labels=[region_name],axis=1))\n",
    "    \n",
    "    # predict the class value itself\n",
    "    y_pred = predictor.predict(df_test.drop(labels=[target_col],axis=1))\n",
    "    \n",
    "    # records the probabilities for the classes on the test set \n",
    "    y_preds.append(y_pred)\n",
    "    \n",
    "    # get the leaderboard DataFrame \n",
    "    d = predictor.leaderboard(silent=True)\n",
    "    \n",
    "    # records the leaderboard DataFrame \n",
    "    leader_board.append(d)\n",
    "    \n",
    "    perfs.append(predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True, silent=True))\n",
    "    \n",
    "    print(f\"EXITING FOLD {k} ---- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now what are the best model(s) in the leaderboard for each fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leader_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = []\n",
    "for i in range(len(leader_board)): \n",
    "    top.append(leader_board[i].iloc[[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.concat(top, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>stack_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.366817</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.332925</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.585271</td>\n",
       "      <td>0.337868</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.376935</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.402662</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.580769</td>\n",
       "      <td>0.341152</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.382727</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.358963</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.381285</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val  fit_time  pred_time_val  stack_level\n",
       "10  weighted_ensemble_k0_l1   0.565891  0.366817       0.000733            1\n",
       "10  weighted_ensemble_k0_l1   0.558140  0.332925       0.000848            1\n",
       "10  weighted_ensemble_k0_l1   0.585271  0.337868       0.000743            1\n",
       "10  weighted_ensemble_k0_l1   0.604651  0.376935       0.000769            1\n",
       "10  weighted_ensemble_k0_l1   0.603846  0.334280       0.000729            1\n",
       "10  weighted_ensemble_k0_l1   0.600000  0.402662       0.000769            1\n",
       "10  weighted_ensemble_k0_l1   0.580769  0.341152       0.000753            1\n",
       "10  weighted_ensemble_k0_l1   0.526923  0.382727       0.000769            1\n",
       "10  weighted_ensemble_k0_l1   0.550000  0.358963       0.000808            1\n",
       "10  weighted_ensemble_k0_l1   0.600000  0.381285       0.000784            1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now retrain over the WHOLE training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first step: get the values, scale and PCA using the whole training data this time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the numpy array containing the training set initial features (grid points)\n",
    "X_train = train_data.drop(labels=[target_col],axis=1).values\n",
    "\n",
    "# get the numpy array containing the training set target values (y)\n",
    "y_train =  train_data.loc[:,target_col].values\n",
    "\n",
    "# -----------\n",
    "# standardize \n",
    "\n",
    "# initialise the scaler (standard scaler)\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# fit on the training set features array, and transform to obtain standardized values\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# apply the transformation on the test set initial features \n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Principal Component Analysis \n",
    "\n",
    "# instantiate the pca class, with percent of variance to keep  \n",
    "\n",
    "skpca = pca.PCA(n_components=percent_variance)\n",
    "\n",
    "# fit on the training initial (standardized) fedatures array, and transform to obtain the PCs\n",
    "X_train_PCs = skpca.fit_transform(X_train_std)\n",
    "\n",
    "# assign the training set PCs to a DataFrame \n",
    "df_train = pd.DataFrame(X_train_PCs) \n",
    "\n",
    "# add the target values to the training DataFrame \n",
    "df_train.loc[:,target_col] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whether to tune or to using bagging and multi-layer stack ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/ensemble/\n",
      "Train Data Rows:    288\n",
      "Train Data Columns: 113\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1. 2. 3.]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 288 data points with 112 features\n",
      "Original Features:\n",
      "\tfloat features: 112\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 112\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.434\t = Validation accuracy score\n",
      "\t2.71s\t = Training runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.4792\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.4236\t = Validation accuracy score\n",
      "\t2.18s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.4757\t = Validation accuracy score\n",
      "\t2.15s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5243\t = Validation accuracy score\n",
      "\t0.26s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5417\t = Validation accuracy score\n",
      "\t0.29s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.4688\t = Validation accuracy score\n",
      "\t1.66s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.4653\t = Validation accuracy score\n",
      "\t13.14s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.5\t = Validation accuracy score\n",
      "\t20.86s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.4306\t = Validation accuracy score\n",
      "\t9.77s\t = Training runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.5556\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 62.31s ...\n"
     ]
    }
   ],
   "source": [
    "if tune: \n",
    "    opath = opath.joinpath('tuned')\n",
    "    if not opath.exists(): \n",
    "        opath.mkdir(parents=True)\n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=False, hyperparameter_tune=True, output_directory=opath) \n",
    "else: \n",
    "    opath = opath.joinpath('ensemble')\n",
    "    if not opath.exists(): \n",
    "        opath.mkdir(parents=True)    \n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True,  hyperparameter_tune=False, output_directory=opath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the fit summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                    model  score_val   fit_time  pred_time_val  stack_level\n",
      "10                weighted_ensemble_k0_l1   0.555556   0.373268       0.000846            1\n",
      "5     KNeighborsClassifierDist_STACKER_l0   0.541667   0.292235       0.641199            0\n",
      "4     KNeighborsClassifierUnif_STACKER_l0   0.524306   0.259798       0.638695            0\n",
      "8          NeuralNetClassifier_STACKER_l0   0.500000  20.858355       0.571039            0\n",
      "1   RandomForestClassifierEntr_STACKER_l0   0.479167   2.704905       0.684169            0\n",
      "3     ExtraTreesClassifierEntr_STACKER_l0   0.475694   2.154379       0.617645            0\n",
      "6           LightGBMClassifier_STACKER_l0   0.468750   1.656782       0.066253            0\n",
      "7           CatboostClassifier_STACKER_l0   0.465278  13.144667       0.070566            0\n",
      "0   RandomForestClassifierGini_STACKER_l0   0.434028   2.712021       0.741319            0\n",
      "9     LightGBMClassifierCustom_STACKER_l0   0.430556   9.771421       0.071333            0\n",
      "2     ExtraTreesClassifierGini_STACKER_l0   0.423611   2.178265       0.622529            0\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_Catboost', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Stack-ensembling used: False \n",
      "Hyperparameter-tuning used: False \n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "Plot summary of models saved to file: saved_models/AUTOGLUON_v2/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_RAIN_targetvar_cat3_categories_target_type/ensemble/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "fit_summary = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_types', 'model_performance', 'model_best', 'model_paths', 'model_fit_times', 'model_pred_times', 'num_bagging_folds', 'stack_ensemble_levels', 'feature_prune', 'hyperparameter_tune', 'hyperparameters_userspecified', 'num_classes', 'model_hyperparams', 'leaderboard'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weighted_ensemble_k0_l1'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_summary['model_best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the leaderboard DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>stack_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.373268</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifierDist_STACKER_l0</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.292235</td>\n",
       "      <td>0.641199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifierUnif_STACKER_l0</td>\n",
       "      <td>0.524306</td>\n",
       "      <td>0.259798</td>\n",
       "      <td>0.638695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetClassifier_STACKER_l0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.858355</td>\n",
       "      <td>0.571039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifierEntr_STACKER_l0</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>2.704905</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesClassifierEntr_STACKER_l0</td>\n",
       "      <td>0.475694</td>\n",
       "      <td>2.154379</td>\n",
       "      <td>0.617645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMClassifier_STACKER_l0</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1.656782</td>\n",
       "      <td>0.066253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatboostClassifier_STACKER_l0</td>\n",
       "      <td>0.465278</td>\n",
       "      <td>13.144667</td>\n",
       "      <td>0.070566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifierGini_STACKER_l0</td>\n",
       "      <td>0.434028</td>\n",
       "      <td>2.712021</td>\n",
       "      <td>0.741319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMClassifierCustom_STACKER_l0</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>9.771421</td>\n",
       "      <td>0.071333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifierGini_STACKER_l0</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>2.178265</td>\n",
       "      <td>0.622529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  score_val   fit_time  \\\n",
       "10                weighted_ensemble_k0_l1   0.555556   0.373268   \n",
       "5     KNeighborsClassifierDist_STACKER_l0   0.541667   0.292235   \n",
       "4     KNeighborsClassifierUnif_STACKER_l0   0.524306   0.259798   \n",
       "8          NeuralNetClassifier_STACKER_l0   0.500000  20.858355   \n",
       "1   RandomForestClassifierEntr_STACKER_l0   0.479167   2.704905   \n",
       "3     ExtraTreesClassifierEntr_STACKER_l0   0.475694   2.154379   \n",
       "6           LightGBMClassifier_STACKER_l0   0.468750   1.656782   \n",
       "7           CatboostClassifier_STACKER_l0   0.465278  13.144667   \n",
       "0   RandomForestClassifierGini_STACKER_l0   0.434028   2.712021   \n",
       "9     LightGBMClassifierCustom_STACKER_l0   0.430556   9.771421   \n",
       "2     ExtraTreesClassifierGini_STACKER_l0   0.423611   2.178265   \n",
       "\n",
       "    pred_time_val  stack_level  \n",
       "10       0.000846            1  \n",
       "5        0.641199            0  \n",
       "4        0.638695            0  \n",
       "8        0.571039            0  \n",
       "1        0.684169            0  \n",
       "3        0.617645            0  \n",
       "6        0.066253            0  \n",
       "7        0.070566            0  \n",
       "0        0.741319            0  \n",
       "9        0.071333            0  \n",
       "2        0.622529            0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values(by='score_val', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluate on the independent test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4930)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.iloc[:,:-1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCs = skpca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba = predictor.predict_proba(pd.DataFrame(X_test_PCs, index=test_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test = pd.DataFrame(test_data.iloc[:,-1].values.astype(np.int32), index=test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test = pd.concat([eval_test, pd.DataFrame(y_hat_proba * 100., index=test_data.index, columns=range(1,4))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the \"SCO\" accuracy, which includes a tolerance of 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy_sco(eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
