{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGLUON experiments using the formatted CSV files as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the environment first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "GCM = 'ECMWF'\n",
    "var_name = 'TMEAN'\n",
    "target_type = 'cat3_categories'\n",
    "region_name = 'NNI'\n",
    "skpca = True \n",
    "standardized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load external modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from shutil import copytree, rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = pathlib.Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import autogluon, tabular prediction, see [https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html](https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../../ml4seas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCM import prepare_data_CSV_to_AUTOML\n",
    "from evaluation import calc_accuracy_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'CSVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_RAIN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_TMEAN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_TMEAN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_RAIN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_RAIN_training_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_std_and_targets_cat3_and_anomalies_TMEAN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_TMEAN_test_set.csv'),\n",
       " PosixPath('/home/nicolasf/research/Smart_Ideas/outputs/CSVs/GCMs_and_targets_cat3_and_anomalies_RAIN_training_set.csv')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dpath.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if standardized: \n",
    "    train_data = pd.read_csv(dpath / f'GCMs_std_and_targets_cat3_and_anomalies_{var_name}_training_set.csv', index_col=0, parse_dates=True) \n",
    "    test_data = pd.read_csv(dpath / f'GCMs_std_and_targets_cat3_and_anomalies_{var_name}_test_set.csv', index_col=0, parse_dates=True)\n",
    "else: \n",
    "    train_data = pd.read_csv(dpath / f'GCMs_and_targets_cat3_and_anomalies_{var_name}_training_set.csv', index_col=0, parse_dates=True) \n",
    "    test_data = pd.read_csv(dpath / f'GCMs_and_targets_cat3_and_anomalies_{var_name}_test_set.csv', index_col=0, parse_dates=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "train_data, GCMs_name_train, _, _ = prepare_data_CSV_to_AUTOML(train_data, GCM=GCM, region_name=region_name, target_type=target_type, scaling=False, doPCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, GCMs_name_test, _, _ = prepare_data_CSV_to_AUTOML(test_data, GCM=GCM, region_name=region_name, target_type=target_type, scaling=False, doPCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4930)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratified k-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the percentage of variance to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_variance = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### root path for saving the parameters of all the AUTOGLUON experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = pathlib.Path('./saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath = saved_models.joinpath(f'./autogluon_exp_SKPCA_{GCM}_pred_{region_name}_reg_{var_name}_targetvar_{target_type}_target_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate models specs will be saved in saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type\n"
     ]
    }
   ],
   "source": [
    "print(f\"intermediate models specs will be saved in {str(opath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not opath.exists(): \n",
    "    opath.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checks on the shape and content of the training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNI_cat3_categories\n"
     ]
    }
   ],
   "source": [
    "target_col = f\"{region_name}_{target_type}\"; print(target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialise a stratified K-Fold object, which will return train and test indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10).split(train_data.drop(labels=[target_col],axis=1).values, train_data.loc[:,target_col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = []\n",
    "# y_preds = []\n",
    "# leader_board = []\n",
    "# perfs = []\n",
    "\n",
    "# for k, (train, test) in enumerate(kfold):\n",
    "    \n",
    "#     X_train = train_data.drop(labels=[target_col],axis=1).iloc[train,:]\n",
    "    \n",
    "#     y_train = train_data.loc[:,target_col].iloc[train,]\n",
    "    \n",
    "#     X_test = train_data.drop(labels=[target_col],axis=1).iloc[test,:]\n",
    "    \n",
    "#     y_test = X_df.loc[:,target_col].iloc[test,]\n",
    "    \n",
    "#     df_train = X_train.copy() \n",
    "#     df_train.loc[:, target_col] = y_train\n",
    "    \n",
    "#     df_test = X_test.copy() \n",
    "#     df_test.loc[:,target_col] = y_test\n",
    "    \n",
    "    \n",
    "#      # fit the task predictor on the training set DataFrame \n",
    "#     predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True, output_directory=opath)\n",
    "    \n",
    "#     # predict the probabilities for each class from the test set features DataFrame (droping the target values column)\n",
    "#     # y_pred_proba = predictor.predict_proba(df_test.drop(labels=[region_name],axis=1))\n",
    "    \n",
    "#     # predict the class value itself\n",
    "#     y_pred = predictor.predict(df_test.drop(labels=[target_col],axis=1))\n",
    "    \n",
    "#     # records the probabilities for the classes on the test set \n",
    "#     y_preds.append(y_pred)\n",
    "    \n",
    "#     # get the leaderboard DataFrame \n",
    "#     d = predictor.leaderboard(silent=True)\n",
    "    \n",
    "#     # records the leaderboard DataFrame \n",
    "#     leader_board.append(d)\n",
    "    \n",
    "#     perfs.append(predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True, silent=True))\n",
    "    \n",
    "#     print(f\"EXITING FOLD {k} ---- \")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 35\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 258 data points with 34 features\n",
      "Original Features:\n",
      "\tfloat features: 34\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 34\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return _load(spec)\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTERING FOLD 0 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6085\t = Validation accuracy score\n",
      "\t2.61s\t = Training runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5853\t = Validation accuracy score\n",
      "\t2.67s\t = Training runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6163\t = Validation accuracy score\n",
      "\t2.12s\t = Training runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6047\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.6434\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6744\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6357\t = Validation accuracy score\n",
      "\t1.26s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6589\t = Validation accuracy score\n",
      "\t4.51s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6589\t = Validation accuracy score\n",
      "\t25.14s\t = Training runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6395\t = Validation accuracy score\n",
      "\t3.75s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6938\t = Validation accuracy score\n",
      "\t0.34s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 50.27s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    258\n",
      "Train Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 258 data points with 32 features\n",
      "Original Features:\n",
      "\tfloat features: 32\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 32\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 0 ---- \n",
      "ENTERING FOLD 1 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6047\t = Validation accuracy score\n",
      "\t2.63s\t = Training runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6008\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.5969\t = Validation accuracy score\n",
      "\t2.16s\t = Training runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6357\t = Validation accuracy score\n",
      "\t2.11s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.6124\t = Validation accuracy score\n",
      "\t0.16s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6589\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6434\t = Validation accuracy score\n",
      "\t1.66s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6667\t = Validation accuracy score\n",
      "\t4.77s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6589\t = Validation accuracy score\n",
      "\t12.65s\t = Training runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6008\t = Validation accuracy score\n",
      "\t4.2s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6667\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.31s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    259\n",
      "Train Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 259 data points with 32 features\n",
      "Original Features:\n",
      "\tfloat features: 32\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 32\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 1 ---- \n",
      "ENTERING FOLD 2 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6448\t = Validation accuracy score\n",
      "\t2.63s\t = Training runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6293\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6293\t = Validation accuracy score\n",
      "\t2.11s\t = Training runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6293\t = Validation accuracy score\n",
      "\t2.15s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.6178\t = Validation accuracy score\n",
      "\t0.19s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6448\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6332\t = Validation accuracy score\n",
      "\t1.74s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.668\t = Validation accuracy score\n",
      "\t4.62s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6873\t = Validation accuracy score\n",
      "\t24.86s\t = Training runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6216\t = Validation accuracy score\n",
      "\t4.26s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.695\t = Validation accuracy score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 51.74s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    259\n",
      "Train Data Columns: 32\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 2 ---- \n",
      "ENTERING FOLD 3 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 259 data points with 31 features\n",
      "Original Features:\n",
      "\tfloat features: 31\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 31\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.6332\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6255\t = Validation accuracy score\n",
      "\t2.67s\t = Training runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6602\t = Validation accuracy score\n",
      "\t2.16s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.668\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.61\t = Validation accuracy score\n",
      "\t0.2s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6371\t = Validation accuracy score\n",
      "\t0.19s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6525\t = Validation accuracy score\n",
      "\t1.47s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.7066\t = Validation accuracy score\n",
      "\t4.55s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6988\t = Validation accuracy score\n",
      "\t10.45s\t = Training runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6486\t = Validation accuracy score\n",
      "\t4.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.7066\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 37.0s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    259\n",
      "Train Data Columns: 32\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 259 data points with 31 features\n",
      "Original Features:\n",
      "\tfloat features: 31\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 31\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 3 ---- \n",
      "ENTERING FOLD 4 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6332\t = Validation accuracy score\n",
      "\t2.64s\t = Training runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5985\t = Validation accuracy score\n",
      "\t2.65s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6062\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.61\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5985\t = Validation accuracy score\n",
      "\t0.14s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.61\t = Validation accuracy score\n",
      "\t0.19s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6564\t = Validation accuracy score\n",
      "\t1.44s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6602\t = Validation accuracy score\n",
      "\t4.9s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6293\t = Validation accuracy score\n",
      "\t8.56s\t = Training runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6293\t = Validation accuracy score\n",
      "\t4.23s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6602\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 35.05s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    259\n",
      "Train Data Columns: 32\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 259 data points with 31 features\n",
      "Original Features:\n",
      "\tfloat features: 31\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 31\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 4 ---- \n",
      "ENTERING FOLD 5 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.5946\t = Validation accuracy score\n",
      "\t2.64s\t = Training runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5985\t = Validation accuracy score\n",
      "\t2.7s\t = Training runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6139\t = Validation accuracy score\n",
      "\t2.15s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6332\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5869\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6062\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6371\t = Validation accuracy score\n",
      "\t1.45s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6448\t = Validation accuracy score\n",
      "\t4.26s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6564\t = Validation accuracy score\n",
      "\t12.93s\t = Training runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6255\t = Validation accuracy score\n",
      "\t4.38s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6718\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.07s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    259\n",
      "Train Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 259 data points with 32 features\n",
      "Original Features:\n",
      "\tfloat features: 32\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 32\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 5 ---- \n",
      "ENTERING FOLD 6 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.5444\t = Validation accuracy score\n",
      "\t2.62s\t = Training runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5753\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.5714\t = Validation accuracy score\n",
      "\t2.17s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.5676\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5444\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.556\t = Validation accuracy score\n",
      "\t0.2s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.5869\t = Validation accuracy score\n",
      "\t1.38s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.5985\t = Validation accuracy score\n",
      "\t4.01s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6255\t = Validation accuracy score\n",
      "\t10.78s\t = Training runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.5753\t = Validation accuracy score\n",
      "\t4.52s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6255\t = Validation accuracy score\n",
      "\t0.36s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.65s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 32\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 6 ---- \n",
      "ENTERING FOLD 7 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 260 data points with 31 features\n",
      "Original Features:\n",
      "\tfloat features: 31\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 31\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t2.67s\t = Training runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6\t = Validation accuracy score\n",
      "\t2.64s\t = Training runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6269\t = Validation accuracy score\n",
      "\t2.13s\t = Training runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t2.14s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5846\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6077\t = Validation accuracy score\n",
      "\t0.16s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6385\t = Validation accuracy score\n",
      "\t1.76s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t3.36s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.65\t = Validation accuracy score\n",
      "\t11.7s\t = Training runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6269\t = Validation accuracy score\n",
      "\t4.61s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6615\t = Validation accuracy score\n",
      "\t0.35s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 37.54s ...\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    260\n",
      "Train Data Columns: 33\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 260 data points with 32 features\n",
      "Original Features:\n",
      "\tfloat features: 32\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 32\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 7 ---- \n",
      "ENTERING FOLD 8 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6269\t = Validation accuracy score\n",
      "\t2.63s\t = Training runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6192\t = Validation accuracy score\n",
      "\t2.68s\t = Training runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6154\t = Validation accuracy score\n",
      "\t2.11s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6192\t = Validation accuracy score\n",
      "\t2.13s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.6115\t = Validation accuracy score\n",
      "\t0.17s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6192\t = Validation accuracy score\n",
      "\t0.19s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6385\t = Validation accuracy score\n",
      "\t1.4s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6538\t = Validation accuracy score\n",
      "\t4.17s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6346\t = Validation accuracy score\n",
      "\t19.1s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.6346\t = Validation accuracy score\n",
      "\t5.2s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6538\t = Validation accuracy score\n",
      "\t0.33s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.95s ...\n",
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/\n",
      "Train Data Rows:    261\n",
      "Train Data Columns: 35\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 261 data points with 34 features\n",
      "Original Features:\n",
      "\tfloat features: 34\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 34\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 8 ---- \n",
      "ENTERING FOLD 9 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.5824\t = Validation accuracy score\n",
      "\t2.64s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5556\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6169\t = Validation accuracy score\n",
      "\t2.13s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.5939\t = Validation accuracy score\n",
      "\t2.16s\t = Training runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5977\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.6169\t = Validation accuracy score\n",
      "\t0.19s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6054\t = Validation accuracy score\n",
      "\t2.0s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6322\t = Validation accuracy score\n",
      "\t3.75s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.636\t = Validation accuracy score\n",
      "\t14.24s\t = Training runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.5862\t = Validation accuracy score\n",
      "\t4.81s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6437\t = Validation accuracy score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 40.61s ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITING FOLD 9 ---- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolasf/anaconda3/envs/ML/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_indices = []\n",
    "y_preds = []\n",
    "leader_board = []\n",
    "perfs = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    \n",
    "    print(f\"ENTERING FOLD {k} ---- \")\n",
    "    \n",
    "    # saves the test indices\n",
    "    test_indices.append(test)\n",
    "    \n",
    "    # get the numpy array containing the training set initial features (grid points)\n",
    "    X_train = train_data.drop(labels=[target_col],axis=1).values[train]\n",
    "    \n",
    "    # get the numpy array containing the training set target values (y)\n",
    "    y_train =  train_data.loc[:,target_col].values[train]\n",
    "    \n",
    "    # get the numpy array containing the test set initial features (grid points)\n",
    "    X_test = train_data.drop(labels=[target_col],axis=1).values[test]\n",
    "    \n",
    "    # get the numpy array containing the test set target values (y)\n",
    "    y_test = train_data.loc[:,target_col].values[test]\n",
    "    \n",
    "    # -----------\n",
    "    # standardize \n",
    "    \n",
    "    # initialise the scaler (standard scaler)\n",
    "    scaler = StandardScaler() \n",
    "    \n",
    "    # fit on the training set features array, and transform to obtain standardized values\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # apply the transformation on the test set initial features \n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Principal Component Analysis \n",
    "    \n",
    "    # instantiate the pca class, with percent of variance to keep  \n",
    "    \n",
    "    skpca = pca.PCA(n_components=percent_variance)\n",
    "    \n",
    "    # fit on the training initial (standardized) fedatures array, and transform to obtain the PCs\n",
    "    X_train_PC = skpca.fit_transform(X_train_std)\n",
    "    \n",
    "    # apply the transformation on the test set standardized features \n",
    "    X_test_PC = skpca.transform(X_test_std)\n",
    "    \n",
    "    # assign the training set PCs to a DataFrame \n",
    "    df_train = pd.DataFrame(X_train_PC) \n",
    "    \n",
    "    # add the target values to the training DataFrame \n",
    "    df_train.loc[:,target_col] = y_train\n",
    "    \n",
    "    # assign the test set Pcs to a DataFrame \n",
    "    df_test = pd.DataFrame(X_test_PC) \n",
    "    \n",
    "    # add the target values to the test DataFrame\n",
    "    df_test.loc[:,target_col] = y_test\n",
    "    \n",
    "    # fit the task predictor on the training set DataFrame \n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True, output_directory=opath)\n",
    "    \n",
    "    # predict the probabilities for each class from the test set features DataFrame (droping the target values column)\n",
    "#     y_pred_proba = predictor.predict_proba(df_test.drop(labels=[region_name],axis=1))\n",
    "    \n",
    "    # predict the class value itself\n",
    "    y_pred = predictor.predict(df_test.drop(labels=[target_col],axis=1))\n",
    "    \n",
    "    # records the probabilities for the classes on the test set \n",
    "    y_preds.append(y_pred)\n",
    "    \n",
    "    # get the leaderboard DataFrame \n",
    "    d = predictor.leaderboard(silent=True)\n",
    "    \n",
    "    # records the leaderboard DataFrame \n",
    "    leader_board.append(d)\n",
    "    \n",
    "    perfs.append(predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True, silent=True))\n",
    "    \n",
    "    print(f\"EXITING FOLD {k} ---- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now what are the best model(s) in the leaderboard for each fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leader_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = []\n",
    "for i in range(len(leader_board)): \n",
    "    top.append(leader_board[i].iloc[[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.concat(top, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>stack_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.693798</td>\n",
       "      <td>0.336677</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.367566</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.694981</td>\n",
       "      <td>0.369833</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.706564</td>\n",
       "      <td>0.349182</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.404439</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.394182</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.625483</td>\n",
       "      <td>0.355122</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.353532</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.332120</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.387655</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val  fit_time  pred_time_val  stack_level\n",
       "10  weighted_ensemble_k0_l1   0.693798  0.336677       0.000752            1\n",
       "10  weighted_ensemble_k0_l1   0.666667  0.367566       0.000835            1\n",
       "10  weighted_ensemble_k0_l1   0.694981  0.369833       0.000752            1\n",
       "10  weighted_ensemble_k0_l1   0.706564  0.349182       0.000731            1\n",
       "10  weighted_ensemble_k0_l1   0.660232  0.404439       0.000753            1\n",
       "10  weighted_ensemble_k0_l1   0.671815  0.394182       0.000827            1\n",
       "10  weighted_ensemble_k0_l1   0.625483  0.355122       0.000743            1\n",
       "10  weighted_ensemble_k0_l1   0.661538  0.353532       0.000765            1\n",
       "10  weighted_ensemble_k0_l1   0.653846  0.332120       0.000740            1\n",
       "10  weighted_ensemble_k0_l1   0.643678  0.387655       0.000763            1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now retrain over the WHOLE training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4930)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first step: get the values, scale and PCA using the whole training data this time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the numpy array containing the training set initial features (grid points)\n",
    "X_train = train_data.drop(labels=[target_col],axis=1).values\n",
    "\n",
    "# get the numpy array containing the training set target values (y)\n",
    "y_train =  train_data.loc[:,target_col].values\n",
    "\n",
    "# -----------\n",
    "# standardize \n",
    "\n",
    "# initialise the scaler (standard scaler)\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# fit on the training set features array, and transform to obtain standardized values\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# apply the transformation on the test set initial features \n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Principal Component Analysis \n",
    "\n",
    "# instantiate the pca class, with percent of variance to keep  \n",
    "\n",
    "skpca = pca.PCA(n_components=percent_variance)\n",
    "\n",
    "# fit on the training initial (standardized) fedatures array, and transform to obtain the PCs\n",
    "X_train_PCs = skpca.fit_transform(X_train_std)\n",
    "\n",
    "# assign the training set PCs to a DataFrame \n",
    "df_train = pd.DataFrame(X_train_PCs) \n",
    "\n",
    "# add the target values to the training DataFrame \n",
    "df_train.loc[:,target_col] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whether to tune or to using bagging and multi-layer stack ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/ensemble/\n",
      "Train Data Rows:    288\n",
      "Train Data Columns: 34\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  [1 2 3]\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == int, but few unique label-values observed)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the finalised models specs (whole training set) will be saved in saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/ensemble\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Generator processed 288 data points with 33 features\n",
      "Original Features:\n",
      "\tfloat features: 33\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tfloat features: 33\n",
      "\tint features: 0\n",
      "\tData preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.5972\t = Validation accuracy score\n",
      "\t2.76s\t = Training runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.5764\t = Validation accuracy score\n",
      "\t2.66s\t = Training runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.6042\t = Validation accuracy score\n",
      "\t2.15s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.5903\t = Validation accuracy score\n",
      "\t2.17s\t = Training runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.5625\t = Validation accuracy score\n",
      "\t0.2s\t = Training runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.5833\t = Validation accuracy score\n",
      "\t0.18s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t0.6354\t = Validation accuracy score\n",
      "\t1.57s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6389\t = Validation accuracy score\n",
      "\t4.61s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t0.6562\t = Validation accuracy score\n",
      "\t16.39s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t0.5833\t = Validation accuracy score\n",
      "\t4.64s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.6562\t = Validation accuracy score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.24s ...\n"
     ]
    }
   ],
   "source": [
    "if tune: \n",
    "    opath = opath.joinpath('tuned')\n",
    "    if not opath.exists(): \n",
    "        opath.mkdir(parents=True)\n",
    "    print(f\"the finalised models specs (whole training set) will be saved in {str(opath)}\\n\")\n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=False, hyperparameter_tune=True, output_directory=opath) \n",
    "else: \n",
    "    opath = opath.joinpath('ensemble')\n",
    "    if not opath.exists(): \n",
    "        opath.mkdir(parents=True)\n",
    "    print(f\"the finalised models specs (whole training set) will be saved in {str(opath)}\\n\")\n",
    "    predictor = task.fit(train_data=df_train, label=target_col, auto_stack=True,  hyperparameter_tune=False, output_directory=opath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the fit summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                                    model  score_val   fit_time  pred_time_val  stack_level\n",
      "10                weighted_ensemble_k0_l1   0.656250   0.399671       0.000774            1\n",
      "8          NeuralNetClassifier_STACKER_l0   0.656250  16.392218       0.578854            0\n",
      "7           CatboostClassifier_STACKER_l0   0.638889   4.613945       0.030033            0\n",
      "6           LightGBMClassifier_STACKER_l0   0.635417   1.567325       0.027179            0\n",
      "2     ExtraTreesClassifierGini_STACKER_l0   0.604167   2.151859       0.546354            0\n",
      "0   RandomForestClassifierGini_STACKER_l0   0.597222   2.763252       0.738505            0\n",
      "3     ExtraTreesClassifierEntr_STACKER_l0   0.590278   2.173850       0.548875            0\n",
      "9     LightGBMClassifierCustom_STACKER_l0   0.583333   4.641741       0.026699            0\n",
      "5     KNeighborsClassifierDist_STACKER_l0   0.583333   0.183550       0.584216            0\n",
      "1   RandomForestClassifierEntr_STACKER_l0   0.576389   2.656675       0.616081            0\n",
      "4     KNeighborsClassifierUnif_STACKER_l0   0.562500   0.199802       0.585651            0\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_Catboost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Stack-ensembling used: False \n",
      "Hyperparameter-tuning used: False \n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "Plot summary of models saved to file: saved_models/autogluon_exp_SKPCA_ECMWF_pred_NNI_reg_TMEAN_targetvar_cat3_categories_target_type/ensemble/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "fit_summary = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_types', 'model_performance', 'model_best', 'model_paths', 'model_fit_times', 'model_pred_times', 'num_bagging_folds', 'stack_ensemble_levels', 'feature_prune', 'hyperparameter_tune', 'hyperparameters_userspecified', 'num_classes', 'model_hyperparams', 'leaderboard'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weighted_ensemble_k0_l1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_summary['model_best']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the leaderboard DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>stack_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weighted_ensemble_k0_l1</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.399671</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetClassifier_STACKER_l0</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>16.392218</td>\n",
       "      <td>0.578854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatboostClassifier_STACKER_l0</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>4.613945</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMClassifier_STACKER_l0</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>1.567325</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifierGini_STACKER_l0</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>2.151859</td>\n",
       "      <td>0.546354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifierGini_STACKER_l0</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>2.763252</td>\n",
       "      <td>0.738505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesClassifierEntr_STACKER_l0</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>2.173850</td>\n",
       "      <td>0.548875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMClassifierCustom_STACKER_l0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>4.641741</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifierDist_STACKER_l0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.183550</td>\n",
       "      <td>0.584216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifierEntr_STACKER_l0</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>2.656675</td>\n",
       "      <td>0.616081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifierUnif_STACKER_l0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.199802</td>\n",
       "      <td>0.585651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model  score_val   fit_time  \\\n",
       "10                weighted_ensemble_k0_l1   0.656250   0.399671   \n",
       "8          NeuralNetClassifier_STACKER_l0   0.656250  16.392218   \n",
       "7           CatboostClassifier_STACKER_l0   0.638889   4.613945   \n",
       "6           LightGBMClassifier_STACKER_l0   0.635417   1.567325   \n",
       "2     ExtraTreesClassifierGini_STACKER_l0   0.604167   2.151859   \n",
       "0   RandomForestClassifierGini_STACKER_l0   0.597222   2.763252   \n",
       "3     ExtraTreesClassifierEntr_STACKER_l0   0.590278   2.173850   \n",
       "9     LightGBMClassifierCustom_STACKER_l0   0.583333   4.641741   \n",
       "5     KNeighborsClassifierDist_STACKER_l0   0.583333   0.183550   \n",
       "1   RandomForestClassifierEntr_STACKER_l0   0.576389   2.656675   \n",
       "4     KNeighborsClassifierUnif_STACKER_l0   0.562500   0.199802   \n",
       "\n",
       "    pred_time_val  stack_level  \n",
       "10       0.000774            1  \n",
       "8        0.578854            0  \n",
       "7        0.030033            0  \n",
       "6        0.027179            0  \n",
       "2        0.546354            0  \n",
       "0        0.738505            0  \n",
       "3        0.548875            0  \n",
       "9        0.026699            0  \n",
       "5        0.584216            0  \n",
       "1        0.616081            0  \n",
       "4        0.585651            0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values(by='score_val', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluate on the independent test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4930)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['(-70.0, 70.0)', '(-70.0, 72.5)', '(-70.0, 75.0)', '(-70.0, 77.5)',\n",
       "       '(-70.0, 80.0)', '(-70.0, 82.5)', '(-70.0, 85.0)', '(-70.0, 87.5)',\n",
       "       '(-70.0, 90.0)', '(-70.0, 92.5)',\n",
       "       ...\n",
       "       '(60.0, 280.0)', '(60.0, 282.5)', '(60.0, 285.0)', '(60.0, 287.5)',\n",
       "       '(60.0, 290.0)', '(60.0, 292.5)', '(60.0, 295.0)', '(60.0, 297.5)',\n",
       "       '(60.0, 300.0)', 'NNI_cat3_categories'],\n",
       "      dtype='object', length=4930)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.iloc[:,:-1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCs = skpca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba = predictor.predict_proba(pd.DataFrame(X_test_PCs, index=test_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test = pd.DataFrame(test_data.iloc[:,-1].values.astype(np.int32), index=test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test = pd.concat([eval_test, pd.DataFrame(y_hat_proba * 100., index=test_data.index, columns=range(1,4))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the \"SCO\" accuracy, which includes a tolerance of 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696969696969697"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy_sco(eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to load a model: `task.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = task.load(opath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09894688, 0.19268957, 0.70836353],\n",
       "       [0.11785357, 0.18408807, 0.69805837],\n",
       "       [0.10740355, 0.2698807 , 0.6227158 ],\n",
       "       [0.16087106, 0.3555479 , 0.48358113],\n",
       "       [0.16122606, 0.28309023, 0.55568373],\n",
       "       [0.11270256, 0.49553704, 0.3917604 ],\n",
       "       [0.10452025, 0.17079857, 0.7246812 ],\n",
       "       [0.09449124, 0.07680687, 0.82870185],\n",
       "       [0.44679683, 0.1486491 , 0.40455404],\n",
       "       [0.51330745, 0.18423092, 0.30246168],\n",
       "       [0.1222893 , 0.08607538, 0.7916353 ],\n",
       "       [0.0928638 , 0.11118511, 0.79595107],\n",
       "       [0.17912257, 0.1925844 , 0.6282931 ],\n",
       "       [0.16430685, 0.14069599, 0.6949972 ],\n",
       "       [0.31478605, 0.34467846, 0.34053546],\n",
       "       [0.25520253, 0.0924872 , 0.65231025],\n",
       "       [0.07510421, 0.05259561, 0.87230015],\n",
       "       [0.11368375, 0.13067058, 0.75564563],\n",
       "       [0.6165532 , 0.15584943, 0.22759743],\n",
       "       [0.15104154, 0.3448202 , 0.5041383 ],\n",
       "       [0.14323203, 0.5409498 , 0.31581813],\n",
       "       [0.09252272, 0.43656048, 0.4709168 ],\n",
       "       [0.40177464, 0.35448384, 0.24374151],\n",
       "       [0.13822867, 0.59535205, 0.26641923],\n",
       "       [0.03677326, 0.12895533, 0.83427143],\n",
       "       [0.06932435, 0.24084747, 0.68982816],\n",
       "       [0.06648784, 0.15450326, 0.77900887],\n",
       "       [0.1274089 , 0.16225275, 0.7103383 ],\n",
       "       [0.29168025, 0.26739147, 0.4409283 ],\n",
       "       [0.6688431 , 0.15185899, 0.17929795],\n",
       "       [0.2722632 , 0.09271193, 0.6350249 ],\n",
       "       [0.2358906 , 0.22128029, 0.5428291 ],\n",
       "       [0.12849191, 0.38232464, 0.4891835 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(pd.DataFrame(X_test_PCs, index=test_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
