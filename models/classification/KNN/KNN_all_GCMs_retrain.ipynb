{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "\n",
    "provider = 'CDS'\n",
    "var_X = 'precip'\n",
    "domain = 'ext_regional'\n",
    "target_var = 'RAIN'\n",
    "target_type = 'cat_3'\n",
    "region_name = 'WNI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load external modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import pathlib\n",
    "from shutil import copytree, rmtree\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = pathlib.Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load local modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../ml4seas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_root_dir\n",
    "from GCM import get_GCM_outputs, shift_dset_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### domain definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_def = {}\n",
    "domain_def['local'] = [150, 200, -50, -10]\n",
    "domain_def['regional'] = [90, 300, -65, 50]\n",
    "domain_def['ext_regional'] = [70, 300, -70, 60]\n",
    "# domain_def['ext_regional'] = [50, 300, -75, 60]\n",
    "domain_def['global'] = [0, 360, -70, 70]\n",
    "domain_def['tropics'] = [0, 360, -40, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the root path for the `data` folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='gdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = 'CDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCMs = ['ECMWF','UKMO','METEO_FRANCE','DWD','CMCC']\n",
    "# GCMs = ['ECMWF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../../../ml4seas/GCM/concat_GCMs.py \n",
    "def concat_GCMs(provider, GCMs, var_name='T2M', period='hindcasts', rpath=None, domain='ext_regional', standardize=True, flatten=True, ensmean=True, step=3): \n",
    "    \"\"\"\n",
    "    Returns many GCM outputs concatenated along the time dimension\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    - provider : str, the provider in ['CDS','IRI','JMA'], no default \n",
    "    - GCMs : list, a list of GCMs in the provider \n",
    "    - period : the period to extract, in ['hindcasts','forecasts']\n",
    "    - rpath : str or pathlib.Path, the path to the 'data' folder \n",
    "    - domain : the domain, in ['local','regional','ext_regional', 'global', 'tropics']\n",
    "    - standardize : Boolean, must be True for 'hindcasts', False for 'forecasts'\n",
    "    - flatten : Boolean, whether or not to flatten the outputs along the spatial (and optionally members) dimension, default to True\n",
    "    - ensmean : Boolean, whether or not to calculate the ensemble mean, default to True\n",
    "    - step : the number of step by which to shift the time index, to align with observed target, default to 3 (assumes seasonal anomalies)\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    - X_data_l : numpy.array containing the data concatenated along the time dimension (axis=0)\n",
    "    - X_data_l_std : if standardized=True, numpy.array containing the standardized data concatenated along the time dimension (axis=0)\n",
    "    - X_index_l :  numpy.array of Python datatimes, containing the index (note that repeated values will be present)\n",
    "    - GCM_records : numpy.array of len(X_index_l) containing the string for the corresponding GCM\n",
    "    - scalers_dict : if standardized=True, dictionnary, with each item (key = GCM) corresponding to fitted scikit-learn StandardScaler() object\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import sys\n",
    "    import pathlib\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    \n",
    "    HOME = pathlib.Path.home()\n",
    "    \n",
    "    sys.path.append(HOME / 'research' / 'Smart_Ideas' / 'code' / 'ml4seas')\n",
    "    \n",
    "    from utils import set_root_dir\n",
    "    from GCM import get_GCM_outputs, shift_dset_time\n",
    "    \n",
    "    GCM_records = []\n",
    "    X_index_l = []\n",
    "    X_data_l = []\n",
    "    \n",
    "    if standardize:\n",
    "        X_data_l_std = []\n",
    "\n",
    "    domain_def = {}\n",
    "    domain_def['local'] = [150, 200, -50, -10]\n",
    "    domain_def['regional'] = [90, 300, -65, 50]\n",
    "    domain_def['ext_regional'] = [70, 300, -70, 60]\n",
    "    # domain_def['ext_regional'] = [50, 300, -75, 60]\n",
    "    domain_def['global'] = [0, 360, -70, 70]\n",
    "    domain_def['tropics'] = [0, 360, -40, 40]    \n",
    "\n",
    "    if standardize: \n",
    "        \n",
    "        scalers_dict = {}\n",
    "    \n",
    "    if isinstance(rpath, str): \n",
    "        rpath = pathlib.Path(rpath)\n",
    "    \n",
    "    for GCM in GCMs: \n",
    "    \n",
    "        print(f\"\\n-----------------   getting {GCM}\")\n",
    "    \n",
    "        dset, coords = get_GCM_outputs(provider=provider, GCM=GCM, var_name=var_name, period=period, rpath=rpath, domain=domain_def[domain], step=step, flatten=flatten, ensmean=ensmean)\n",
    "        \n",
    "        if 'valid_time' in dset.coords: \n",
    "            dset = dset.drop('valid_time')        \n",
    "            \n",
    "        dset = shift_dset_time(dset, step=step)\n",
    "        \n",
    "        X_data = dset[var_name.lower()].data\n",
    "        \n",
    "        X_index = dset['time'].to_index().to_pydatetime()\n",
    "        \n",
    "        if standardize: \n",
    "        \n",
    "            scaler = StandardScaler() \n",
    "\n",
    "            scaler = scaler.fit(X_data)\n",
    "\n",
    "            scalers_dict[GCM] = scaler\n",
    "\n",
    "            X_data_std = scaler.transform(X_data)\n",
    "\n",
    "        # append and records \n",
    "        \n",
    "        GCM_records.append(np.repeat([GCM], len(X_index)))\n",
    "        \n",
    "        X_index_l.append(X_index)\n",
    "        \n",
    "        X_data_l.append(X_data)\n",
    "\n",
    "        if standardize: \n",
    "        \n",
    "            X_data_l_std.append(X_data_std)\n",
    "        \n",
    "    GCM_records = np.array(list(itertools.chain(*GCM_records)))\n",
    "\n",
    "    X_index_l = np.array(list(itertools.chain(*X_index_l)))\n",
    "\n",
    "    X_data_l = np.array(list(itertools.chain(*X_data_l)))\n",
    "\n",
    "    if standardize: \n",
    "    \n",
    "        X_data_l_std = np.array(list(itertools.chain(*X_data_l_std)))\n",
    "\n",
    "        return X_data_l, X_data_l_std, X_index_l, GCM_records, scalers_dict\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        return X_data_l, X_index_l, GCM_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='gdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/PRECIP\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/PRECIP/ECMWF_PRECIP_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/ECMWF/PRECIP/ECMWF_PRECIP_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/PRECIP\n",
      "number of files in the archive: 287\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/PRECIP/UKMO_PRECIP_seasonal_anomalies_interp_1993_02.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/UKMO/PRECIP/UKMO_PRECIP_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/PRECIP\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/PRECIP/METEO_FRANCE_PRECIP_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/METEO_FRANCE/PRECIP/METEO_FRANCE_PRECIP_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/PRECIP\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/PRECIP/DWD_PRECIP_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/DWD/PRECIP/DWD_PRECIP_seasonal_anomalies_interp_2016_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/PRECIP\n",
      "number of files in the archive: 288\n",
      "first file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/PRECIP/CMCC_PRECIP_seasonal_anomalies_interp_1993_01.nc\n",
      "last file is /media/nicolasf/GDATA/END19101/Working/data/GCMs/processed/hindcasts/CDS/CMCC/PRECIP/CMCC_PRECIP_seasonal_anomalies_interp_2016_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_train, X_data_train_std, X_index_train, GCM_records_train, scalers_dict = concat_GCMs(provider, GCMs, var_name=var_X.upper(), period='hindcasts', rpath=rpath, domain='ext_regional', standardize=True, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = set_root_dir(root='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------   getting ECMWF\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/PRECIP\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/PRECIP/ECMWF_PRECIP_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/ECMWF/PRECIP/ECMWF_PRECIP_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting UKMO\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/PRECIP\n",
      "number of files in the archive: 28\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/PRECIP/UKMO_PRECIP_seasonal_anomalies_interp_2017_09.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/UKMO/PRECIP/UKMO_PRECIP_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting METEO_FRANCE\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/PRECIP\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/PRECIP/METEO_FRANCE_PRECIP_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/METEO_FRANCE/PRECIP/METEO_FRANCE_PRECIP_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting DWD\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/PRECIP\n",
      "number of files in the archive: 36\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/PRECIP/DWD_PRECIP_seasonal_anomalies_interp_2017_01.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/DWD/PRECIP/DWD_PRECIP_seasonal_anomalies_interp_2019_12.nc\n",
      "\n",
      "-----------------   getting CMCC\n",
      "reading files from /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/PRECIP\n",
      "number of files in the archive: 14\n",
      "Something wrong with the number of files in the list for the forecasts period, the length is 14\n",
      "first file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/PRECIP/CMCC_PRECIP_seasonal_anomalies_interp_2018_11.nc\n",
      "last file is /home/nicolasf/research/Smart_Ideas/data/GCMs/processed/forecasts/CDS/CMCC/PRECIP/CMCC_PRECIP_seasonal_anomalies_interp_2019_12.nc\n"
     ]
    }
   ],
   "source": [
    "X_data_test, X_index_test, GCM_records_test = concat_GCMs(provider, GCMs, var_name=var_X.upper(), period='forecasts', rpath=rpath, domain='ext_regional', standardize=False, flatten=True, ensmean=True, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4929)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 4929)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply the standard scalers to the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECMWF': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'UKMO': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'METEO_FRANCE': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'DWD': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'CMCC': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test_std = []\n",
    "for GCM in np.unique(GCM_records_test): \n",
    "    X_sub = X_data_test[GCM_records_test == GCM,:]\n",
    "    X_sub_std = scalers_dict[GCM].transform(X_sub)\n",
    "    X_data_test_std.append(X_sub_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test_std = np.array(list(itertools.chain(*X_data_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4929)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_test_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TARGETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath_target = HOME / 'research' / 'Smart_Ideas' / 'outputs' / 'targets' / 'NZ_regions' / 'NZ_6_regions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for reg in ['NNI','WNI','ENI','NSI','WSI','ESI']: \n",
    "    target = pd.read_csv(dpath_target / target_var / reg / f'TS_NZ_region_{reg}_{target_var}_3_quantiles_anoms.csv', index_col=0, parse_dates=True)\n",
    "    target.columns = pd.MultiIndex.from_product([[reg],target.columns])\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.concat(targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">NNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WNI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ENI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">WSI</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ESI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "      <th>Rain_bc</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>anomalies</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-03-31</th>\n",
       "      <td>470.822673</td>\n",
       "      <td>3</td>\n",
       "      <td>176.364977</td>\n",
       "      <td>357.294404</td>\n",
       "      <td>3</td>\n",
       "      <td>49.163323</td>\n",
       "      <td>472.045206</td>\n",
       "      <td>3</td>\n",
       "      <td>180.723225</td>\n",
       "      <td>498.174979</td>\n",
       "      <td>3</td>\n",
       "      <td>66.560252</td>\n",
       "      <td>783.318801</td>\n",
       "      <td>3</td>\n",
       "      <td>143.904216</td>\n",
       "      <td>221.08315</td>\n",
       "      <td>3</td>\n",
       "      <td>49.951240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-30</th>\n",
       "      <td>546.720000</td>\n",
       "      <td>3</td>\n",
       "      <td>229.631158</td>\n",
       "      <td>440.482174</td>\n",
       "      <td>3</td>\n",
       "      <td>121.697362</td>\n",
       "      <td>492.918286</td>\n",
       "      <td>3</td>\n",
       "      <td>181.818099</td>\n",
       "      <td>564.466858</td>\n",
       "      <td>3</td>\n",
       "      <td>129.367183</td>\n",
       "      <td>690.960327</td>\n",
       "      <td>3</td>\n",
       "      <td>94.298941</td>\n",
       "      <td>215.23890</td>\n",
       "      <td>3</td>\n",
       "      <td>51.450578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-31</th>\n",
       "      <td>493.002426</td>\n",
       "      <td>3</td>\n",
       "      <td>134.029467</td>\n",
       "      <td>523.612630</td>\n",
       "      <td>3</td>\n",
       "      <td>167.590461</td>\n",
       "      <td>514.622032</td>\n",
       "      <td>3</td>\n",
       "      <td>174.868212</td>\n",
       "      <td>652.528876</td>\n",
       "      <td>3</td>\n",
       "      <td>163.604985</td>\n",
       "      <td>730.426131</td>\n",
       "      <td>3</td>\n",
       "      <td>78.714666</td>\n",
       "      <td>294.27635</td>\n",
       "      <td>3</td>\n",
       "      <td>126.515812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-06-30</th>\n",
       "      <td>429.186337</td>\n",
       "      <td>2</td>\n",
       "      <td>13.302417</td>\n",
       "      <td>404.922302</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.359534</td>\n",
       "      <td>306.615937</td>\n",
       "      <td>1</td>\n",
       "      <td>-71.251663</td>\n",
       "      <td>579.009926</td>\n",
       "      <td>2</td>\n",
       "      <td>25.933292</td>\n",
       "      <td>662.720245</td>\n",
       "      <td>2</td>\n",
       "      <td>1.927881</td>\n",
       "      <td>165.33315</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.559937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-07-31</th>\n",
       "      <td>549.575990</td>\n",
       "      <td>3</td>\n",
       "      <td>77.774812</td>\n",
       "      <td>407.600080</td>\n",
       "      <td>1</td>\n",
       "      <td>-53.438670</td>\n",
       "      <td>368.729460</td>\n",
       "      <td>1</td>\n",
       "      <td>-65.591395</td>\n",
       "      <td>602.019278</td>\n",
       "      <td>2</td>\n",
       "      <td>18.614145</td>\n",
       "      <td>606.331144</td>\n",
       "      <td>2</td>\n",
       "      <td>-34.887512</td>\n",
       "      <td>187.18665</td>\n",
       "      <td>3</td>\n",
       "      <td>12.600620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NNI                           WNI                    \\\n",
       "               Rain_bc cat_3   anomalies     Rain_bc cat_3   anomalies   \n",
       "time                                                                     \n",
       "1979-03-31  470.822673     3  176.364977  357.294404     3   49.163323   \n",
       "1979-04-30  546.720000     3  229.631158  440.482174     3  121.697362   \n",
       "1979-05-31  493.002426     3  134.029467  523.612630     3  167.590461   \n",
       "1979-06-30  429.186337     2   13.302417  404.922302     2   -9.359534   \n",
       "1979-07-31  549.575990     3   77.774812  407.600080     1  -53.438670   \n",
       "\n",
       "                   ENI                           NSI                    \\\n",
       "               Rain_bc cat_3   anomalies     Rain_bc cat_3   anomalies   \n",
       "time                                                                     \n",
       "1979-03-31  472.045206     3  180.723225  498.174979     3   66.560252   \n",
       "1979-04-30  492.918286     3  181.818099  564.466858     3  129.367183   \n",
       "1979-05-31  514.622032     3  174.868212  652.528876     3  163.604985   \n",
       "1979-06-30  306.615937     1  -71.251663  579.009926     2   25.933292   \n",
       "1979-07-31  368.729460     1  -65.591395  602.019278     2   18.614145   \n",
       "\n",
       "                   WSI                          ESI                    \n",
       "               Rain_bc cat_3   anomalies    Rain_bc cat_3   anomalies  \n",
       "time                                                                   \n",
       "1979-03-31  783.318801     3  143.904216  221.08315     3   49.951240  \n",
       "1979-04-30  690.960327     3   94.298941  215.23890     3   51.450578  \n",
       "1979-05-31  730.426131     3   78.714666  294.27635     3  126.515812  \n",
       "1979-06-30  662.720245     2    1.927881  165.33315     2   -0.559937  \n",
       "1979-07-31  606.331144     2  -34.887512  187.18665     3   12.600620  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_anomalies = targets.loc[:, (slice(None), [\"anomalies\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles = targets.loc[:, (slice(None), [\"cat_3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_anomalies.columns = targets_anomalies.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_terciles.columns = target_terciles.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target choice here (anomalies or tercile class, and region_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_type == 'cat_3': \n",
    "    y = target_terciles.loc[:,region_name]\n",
    "elif target_type == 'anomalies': \n",
    "    y = target_anomalies.loc[:,region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Now going agead with TARGET WNI, cat_3 ------------------------ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\n\\nNow going agead with TARGET {region_name}, {target_type} ------------------------ \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the list of repeated index to select the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.loc[X_index_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_index_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y.reindex(X_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now randomize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the shuffled indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_indexes = np.random.randint(0, len(X_data_train_std), len(X_data_train_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_test_indexes = np.random.randint(0, len(X_data_test_std), len(X_data_test_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply the shuffled indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_train_std_shuffled = X_data_train_std[shuffled_train_indexes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_test_std_shuffled = X_data_test_std[shuffled_test_indexes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_shuffled = y_train[shuffled_train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_shuffled = y_test[shuffled_test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_test_indexes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN now with stratified k fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_data_train_std_shuffled\n",
    "y = y_train_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 4929)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_tr, X_te = X[train_index], X[test_index]\n",
    "    \n",
    "    y_tr, y_te = y[train_index], y[test_index]\n",
    "\n",
    "    knn = KNN(n_neighbors=n_neighbors, metric='minkowski', weights='distance', p=3, n_jobs=-1)\n",
    "\n",
    "    knn.fit(X_tr, y_tr)\n",
    "\n",
    "    acc_score.append(knn.score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8275862068965517,\n",
       " 0.8896551724137931,\n",
       " 0.8758620689655172,\n",
       " 0.8344827586206897,\n",
       " 0.8055555555555556,\n",
       " 0.8251748251748252,\n",
       " 0.8671328671328671,\n",
       " 0.8601398601398601,\n",
       " 0.8671328671328671,\n",
       " 0.7902097902097902]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(n_neighbors=n_neighbors, metric='minkowski', weights='distance', p=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=1, p=3,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_data_train_std_shuffled, y_train_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = knn.predict(X_data_test_std_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_probs = knn.predict_proba(X_data_test_std_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2019-08-31    2.0\n",
       "2019-10-31    1.0\n",
       "2017-12-31    1.0\n",
       "2019-05-31    2.0\n",
       "2018-10-31    1.0\n",
       "             ... \n",
       "2020-01-31    NaN\n",
       "2019-08-31    2.0\n",
       "2018-06-30    3.0\n",
       "2017-06-30    3.0\n",
       "2019-07-31    1.0\n",
       "Name: WNI, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_shuffled = y_test_shuffled.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_shuffled.loc[:,'y_hat'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_shuffled = y_test_shuffled.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36231884057971014"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_shuffled.loc[:,region_name].values == y_test_shuffled.y_hat.values).sum() / len(y_test_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate a model that is re-trained every month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 4929)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat_train = X_data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat_test = X_data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mat_train = y_train.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 4929)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2017-04-30    3.0\n",
       "2017-05-31    3.0\n",
       "2017-06-30    3.0\n",
       "2017-07-31    1.0\n",
       "2017-08-31    2.0\n",
       "             ... \n",
       "2019-11-30    1.0\n",
       "2019-12-31    1.0\n",
       "2020-01-31    NaN\n",
       "2020-02-29    NaN\n",
       "2020-03-31    NaN\n",
       "Name: WNI, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat_test = X_mat_test[~np.isnan(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 4929)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[~np.isnan(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = []\n",
    "y_hat_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)): \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(X_mat_train)\n",
    "    \n",
    "    X_mat_train_std = scaler.transform(X_mat_train)\n",
    "    \n",
    "    X_mat_test_std = scaler.transform(X_mat_test[i,:].reshape(1, -1))\n",
    "    \n",
    "    knn = KNN(n_neighbors=n_neighbors, metric='minkowski', weights='distance', p=3, n_jobs=-1)\n",
    "    \n",
    "    knn.fit(X_mat_train_std, y_mat_train)\n",
    "    \n",
    "    y_hat.append(knn.predict(X_mat_test_std))\n",
    "    \n",
    "    y_hat_probs.append(knn.predict_proba(X_mat_test_std))\n",
    "    \n",
    "    X_mat_train = np.r_[X_mat_train, X_mat_test[i,:].reshape(1,-1)]\n",
    "    \n",
    "    y_mat_train = np.append(y_mat_train, y_test[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_probs = np.array(y_hat_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = y_test.to_frame(name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.loc[:,'y_hat'] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_all.loc[:,'y_hat_probs'] = y_hat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_all.y_hat.values == y_all.y.values).sum() / len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.index.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date =  y_all.index.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.loc[date,:].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_ = []\n",
    "for date in y_all.index.unique(): \n",
    "    print(f\"{date:%Y-%m} number of available GCMs: {len(y_all.loc[date,:])}\")\n",
    "    maj_.append(y_all.loc[date,:].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj = pd.concat(maj_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(maj.y_hat.values == maj.y.values).sum() / len(maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
